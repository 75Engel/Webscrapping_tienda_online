{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estudio sobre la tienda on-line de:\n",
    "\n",
    "## [AMANTIS](https://www.amantis.net/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Por qué este estudio?\n",
    "\n",
    "Primero, este es un trabajo de análisis de datos y de predicción sobre una tienda on-line. Creo que las personas que veamos esta documentación somos adultas y lo suficientemente maduras para asumir que el sexo es parte de nuestra vida.\n",
    "\n",
    "Por este motivo, el hacer un estudio sobre una tienda on-line erótica es lo mismo que realizarlo sobre una tienda de ropa, muebles, un supermercado,...\n",
    "\n",
    "Segundo, yo soy usuario registrado de esta tienda on-line. No solo realizo compras para mí o para mi pareja sino también para otras personas. \n",
    "Es por este motivo el que recibo periódicamente correos de ofertas de esta tienda on-line y es aquí en donde entra mi motivación personal.\n",
    "\n",
    "Los correos que envían a sus usuarios están basados en ofertas que lanzan (estas ofertas están basadas en rebajas) y son muy arbitrarias. Suelo recibir correos de ofertas de determinados productos de los que NO he realizado una compra del mismo o similares. \n",
    "\n",
    "Por este motivo, considero interesante poder realizar algún tipo de estudio sobre los productos que tengan en la tienda y poder dar una mejor experiencia al comprador."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones para el proyecto.\n",
    "\n",
    "Este proyecto está estructurado en 4 partes:\n",
    "\n",
    "- Obtención y tratamiento de datos de la página web, a partir de *Webscrapping* y su manipulación para poder tratarlos a través de las librerías de *pandas* y *numpy* y su almacenamiento en una *Base de datos Relacional*, dada la posibilidad de limitar los campos a realizar y la atomización de los datos.\n",
    "   - A su vez se realizará algún tipo de visionado de los datos obtenidos para ver diversos aspectos a tener en cuenta.\n",
    "- Generación de nuevas variables, *featuring engineering*, para poder dar una mejor visión de los productos que ofrecen en la tienda.\n",
    "    - A través de la generación de estas nuevas variables, pretendemos dar un visionario más completo sobre la relación de las diversas variables entre sí y los usuarios.\n",
    "    - Estas variables pueden ser obtenidas a través de *pandas*, *RegEx* y *NLP*.\n",
    "- Análisis de la información obtenida y generada para ver la relación existente entre usuarios, productos, fechas...\n",
    "   - Esta información será aplicada a partir de diversas queries de la base de datos a utilizar y con las librerías de *pandas*, *matplotlib* y *seaborn*.\n",
    "- Generación de modelados de los datos obtenidos para establecer gustos de los usuarios y dar sugerencia de otros productos que tengan etiquetas similares.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Obtención y tratamiento de los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la **URL** *'https://www.amantis.net/productos-amantis/'* vamos a realizar un recorrido por las diferentes páginas que dispone y en donde están alojadas las **URLs** de los diferentes productos que disponen.\n",
    "\n",
    "Una vez que accedemos a la dirección de cada producto, vemos que hay una serie de datos que queremos recoger de la misma:\n",
    "> Nombre.\n",
    "> Precio del producto.\n",
    ">\n",
    "> Precio rebajado del producto.\n",
    ">\n",
    "> Descripción e información sobre el producto (tamaño, duración de baterias, limpieza ...). \n",
    ">\n",
    "> Comentarios.\n",
    "\n",
    "Dentro de comentarios disponemos de más información, que consideramos interesante:\n",
    "> Usuario.\n",
    ">\n",
    "> Rating.\n",
    ">\n",
    "> Fecha comentario.\n",
    ">\n",
    "> Cuerpo del comentario.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de la librería para Webscrapping *Beautiful Soap* procederemos a extraer esta información y en determinados casos a tratarla para poder trabajar con ella.\n",
    "\n",
    "Para ello cargaremos las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina 1\n",
      "Pagina 2\n",
      "Pagina 3\n",
      "Pagina 4\n",
      "Pagina 5\n",
      "Pagina 6\n",
      "Pagina 7\n",
      "Pagina 8\n",
      "Pagina 9\n",
      "Pagina 10\n",
      "Pagina 11\n",
      "Pagina 12\n",
      "Pagina 13\n",
      "Pagina 14\n",
      "Pagina 15\n",
      "Pagina 16\n",
      "Pagina 17\n",
      "Pagina 18\n",
      "Pagina 19\n",
      "Pagina 20\n",
      "Pagina 21\n",
      "Pagina 22\n",
      "Pagina 23\n",
      "Pagina 24\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11551 entries, 0 to 11550\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   ID       11551 non-null  int64 \n",
      " 1   DATE     11551 non-null  object\n",
      " 2   RATIO    11551 non-null  int64 \n",
      " 3   USERS    11551 non-null  object\n",
      " 4   COMMENT  11551 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 451.3+ KB\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.amantis.net/productos-amantis/\"              # lista productos\n",
    "url_principal=\"https://www.amantis.net/\"                        # productos\n",
    "# pages= np.arange(1,5)\n",
    "pages= np.arange(1, 25)\n",
    "\n",
    "'''Listas a generar con la información de los productos'''\n",
    "lista_URLs = []\n",
    "name=[]\n",
    "regular_prices=[]\n",
    "new_price=[]\n",
    "info=[]\n",
    "user_comments=[]\n",
    "comment=[]\n",
    "date=[]\n",
    "ratings=[]\n",
    "id=[]\n",
    "comentarios=[]\n",
    "\n",
    "\n",
    "\n",
    "'''Generamos 2 diccionarios con los datos importantes para ingresar en una BBDD'''\n",
    "\n",
    "diccionario_datos_productos={\"ID\":id,\"NAME\":name,\"INFO\":info,\"LISTA_URL\":lista_URLs,\"REGULAR_PRICE\":regular_prices,\"DISCOUNT_PRICE\":new_price}\n",
    "\n",
    "diccionario_comentarios_productos={\"ID\":id,\"COMENTARIOS\":comentarios}\n",
    "\n",
    "\n",
    "\n",
    "''' Obtenemos las URLs de los productos para entrar luego en sus URLS y extraer la información'''\n",
    "\n",
    "for page in pages:\n",
    "    if page == 1:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url\n",
    "        response = requests.get(url)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        productos = soup.find_all(class_='caption')\n",
    "        for producto in productos[9:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "        \n",
    "    else:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url+'page' + str(page)+'/'\n",
    "        response = requests.get(URL)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        productos = soup.find_all(class_='caption')\n",
    "        for producto in productos[9:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "\n",
    "\n",
    "for i in range(len(lista_URLs)):\n",
    "    id.append(i)\n",
    "\n",
    "    \n",
    "'''Extraemos la información de cada producto existente'''\n",
    "\n",
    "for URL in lista_URLs:\n",
    "    url_product=URL\n",
    "    response_product = requests.get(url_product)\n",
    "    soup_product = bs(response_product.text, 'lxml')\n",
    "    user_comments_product=[]\n",
    "    date_comments_product=[]\n",
    "    comments_product=[]\n",
    "    rating=[]\n",
    "\n",
    "    titulos=soup_product.find_all(\"h1\",class_=\"h3\")\n",
    "    for titulo in titulos:\n",
    "        nombre=titulo.get_text(strip=True)\n",
    "        name.append(nombre)\n",
    "\n",
    "    all_price = soup_product.find_all(\"div\", class_=\"productoPrecio pull-right tdd_precio\")                        \n",
    "    for price_container in all_price:                                                                    \n",
    "        try:\n",
    "            special_price = price_container.find(\"span\", class_=\"productSpecialPrice\")\n",
    "            if special_price:\n",
    "                item_price = float(special_price.get_text(strip=True).replace(\",\", \".\").split('€')[0])\n",
    "                new_price.append(item_price)\n",
    "                regular_price = price_container.find(\"del\").get_text(strip=True)\n",
    "                item_regular_price = float(regular_price.replace(\",\", \".\").split('€')[0])\n",
    "                regular_prices.append(item_regular_price)\n",
    "            else:\n",
    "                regular_price = price_container.find(\"span\").get_text(strip=True)\n",
    "                item_regular_price = float(regular_price.replace(\",\", \".\").split('€')[0])\n",
    "                new_price.append(item_regular_price)\n",
    "                regular_prices.append(None)\n",
    "        except:\n",
    "            new_price.append(None)\n",
    "            regular_prices.append(None)\n",
    "\n",
    "    description=soup_product.find(\"div\", class_=\"description\") \n",
    "    information=description.get_text().split('\\n')[1:]\n",
    "    documentation = ''.join(information)\n",
    "    info.append(documentation)\n",
    "\n",
    "\n",
    "    '''Vamos a obtener los datos de los comentarios de los usuarios'''\n",
    "\n",
    "    all_user_comments = soup_product.find_all(\"span\", class_=\"name-user\") \n",
    "    for user_comment in all_user_comments:\n",
    "        user_comments_product.append(user_comment.get_text(strip=True))\n",
    "    user_comments.append(user_comments_product)\n",
    "\n",
    "    all_dates = soup_product.find_all(\"span\", class_=\"date\")  \n",
    "    for dates in all_dates:\n",
    "        dates_text=dates.get_text(strip=True)\n",
    "        # dates=datetime.strftime(dates, '%dd/%mm/%Y')\n",
    "        date_comments_product.append(dates_text)\n",
    "        # date_object = datetime.strptime(date_comments_product)\n",
    "    date.append(date_comments_product)\n",
    "\n",
    "    all_comments = soup_product.find_all(\"p\")\n",
    "    for formats in all_comments[-len(date_comments_product):]:\n",
    "        comments_product.append(formats.get_text(strip=True))\n",
    "    comment.append(comments_product)\n",
    "\n",
    "    hearts = soup_product.find_all('div', class_= 'box-description')\n",
    "    for heart in hearts:\n",
    "        heart_rating = heart.find_all('span', class_= 'fas fa-heart')\n",
    "        num_hearts = len(heart_rating)\n",
    "        rating.append(num_hearts)\n",
    "    ratings.append(rating)\n",
    "\n",
    "    datos = list(zip( date_comments_product,rating, user_comments_product,comments_product ))\n",
    "    comentarios.append(datos)\n",
    "\n",
    "for i, regular_price in enumerate(regular_prices):\n",
    "    if regular_price is None:\n",
    "        regular_prices[i] = new_price[i]\n",
    "\n",
    "'''Generamos un dataframe con este diccionario para poder trabajar con los mismos y generar una nueva estructura para poder trabajar con ella'''\n",
    "\n",
    "comentarios_productos=pd.DataFrame(diccionario_comentarios_productos)\n",
    "\n",
    "id=[]\n",
    "comments=[]\n",
    "date=[]\n",
    "ratio=[]\n",
    "users=[]\n",
    "comment=[]\n",
    "\n",
    "comentarios=pd.DataFrame()\n",
    "diccionario={\"id\":id,\"comments\":comments}\n",
    "\n",
    "for id_product,n_comments in enumerate (comentarios_productos['COMENTARIOS']):\n",
    "    # print(\"Imprimiendo texto del indice\",id_product)\n",
    "    # print(\"Imprimiento n_comentarios\",len(n_comments))\n",
    "    for i in n_comments:\n",
    "        # print(\"id\",id_product,\"coments\",comments)\n",
    "        id.append(id_product)\n",
    "        comments.append(i)\n",
    "\n",
    "\n",
    "for j in range(len(diccionario['comments'])):\n",
    "    date.append(diccionario['comments'][j][0])\n",
    "    ratio.append(diccionario['comments'][j][1])\n",
    "    users.append(diccionario['comments'][j][2])\n",
    "    comment.append(diccionario['comments'][j][3])\n",
    "\n",
    "\n",
    "comentarios['ID']=pd.Series(id)\n",
    "comentarios['DATE']=pd.Series(date)\n",
    "comentarios['RATIO']=pd.Series(ratio)\n",
    "comentarios['USERS']=pd.Series(users)\n",
    "comentarios['COMMENT']=pd.Series(comment)\n",
    "comentarios.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar los datos que existen en los dos diccionarios.\n",
    "\n",
    "Para ello pasaremos el diccionario de productos a un Dataframe y después haremos un estudio de los mismos.\n",
    "\n",
    "Vamos a ver si cuántos duplicados hay en este Dataframe, ya que navegando por la web hemos visto algún producto repetido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 576 entries, 0 to 575\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ID              576 non-null    int64  \n",
      " 1   NAME            576 non-null    object \n",
      " 2   INFO            576 non-null    object \n",
      " 3   LISTA_URL       576 non-null    object \n",
      " 4   REGULAR_PRICE   576 non-null    float64\n",
      " 5   DISCOUNT_PRICE  576 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 27.1+ KB\n"
     ]
    }
   ],
   "source": [
    "productos=pd.DataFrame(diccionario_datos_productos)\n",
    "productos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11551 entries, 0 to 11550\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   ID       11551 non-null  int64 \n",
      " 1   DATE     11551 non-null  object\n",
      " 2   RATIO    11551 non-null  int64 \n",
      " 3   USERS    11551 non-null  object\n",
      " 4   COMMENT  11551 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 451.3+ KB\n"
     ]
    }
   ],
   "source": [
    "comentarios.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OISHi, Camiseta de rejilla negra con mangas                     2\n",
       "WARRIOR, suave casco vibrador para masaje integral              2\n",
       "Columpio sexual de amantis, el asistente postural definitivo    2\n",
       "GALGA, sofisticadas braguitas-arnés de amantis                  2\n",
       "DOBERMANA, arnés fino y de doble anilla                         2\n",
       "                                                               ..\n",
       "SAREA, body de calentamiento de rejilla ancha                   1\n",
       "JUSTISSE CHOCKER, unisex con argolla                            1\n",
       "ADA, Vagina translúcida extra suave de amantis                  1\n",
       "LOCOMOTION rugged, tu sex-machine con vibración y ventosa       1\n",
       "JUSTISSE BACK - mordaza de bola con esposas                     1\n",
       "Name: NAME, Length: 550, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productos.NAME.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminando duplicados de los dos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 550 entries, 0 to 575\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ID              550 non-null    int64  \n",
      " 1   NAME            550 non-null    object \n",
      " 2   INFO            550 non-null    object \n",
      " 3   LISTA_URL       550 non-null    object \n",
      " 4   REGULAR_PRICE   550 non-null    float64\n",
      " 5   DISCOUNT_PRICE  550 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 30.1+ KB\n"
     ]
    }
   ],
   "source": [
    "noduplicated_product = productos.drop_duplicates(subset='NAME', keep='first')\n",
    "noduplicated_product.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10659 entries, 0 to 11550\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   ID       10659 non-null  int64 \n",
      " 1   DATE     10659 non-null  object\n",
      " 2   RATIO    10659 non-null  int64 \n",
      " 3   USERS    10659 non-null  object\n",
      " 4   COMMENT  10659 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 499.6+ KB\n"
     ]
    }
   ],
   "source": [
    "removed_id = productos[productos.duplicated(subset='NAME', keep='first')]['ID']\n",
    "noduplicated_comments = comentarios[~comentarios['ID'].isin(productos[productos['ID'].isin(removed_id)]['ID'])]\n",
    "noduplicated_comments.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generamos nuevas variables dentro del dataframe de **productos**.\n",
    "\n",
    "Vamos a crear 2 nuevas columnas a partir de *Name* y *Description*, donde dejaremos el nombre del producto y su slogan por un lado y por otro la descripción y las características por otro.\n",
    "\n",
    "En principio son variables que no necesitaremos para estos estudios pero las guardaremos por si hay que hacer algún estudio posterior de las mismas (comparativas de productos similares de esta página web o de otras páginas web, por ejemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 550 entries, 0 to 575\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ID              550 non-null    int64  \n",
      " 1   NAME            550 non-null    object \n",
      " 2   INFO            550 non-null    object \n",
      " 3   LISTA_URL       550 non-null    object \n",
      " 4   REGULAR_PRICE   550 non-null    float64\n",
      " 5   DISCOUNT_PRICE  550 non-null    float64\n",
      " 6   PRODUCT         550 non-null    object \n",
      " 7   SLOGAN          454 non-null    object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 38.7+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\3431089402.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  noduplicated_product['NAME'] = noduplicated_product['NAME'].str.replace(r'-(?=\\w)', '_')\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\3431089402.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product['NAME'] = noduplicated_product['NAME'].str.replace(r'-(?=\\w)', '_')\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\3431089402.py:2: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  noduplicated_product[['PRODUCT', 'SLOGAN']] = noduplicated_product['NAME'].str.split('[,-.]', 1, expand=True)\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\3431089402.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product[['PRODUCT', 'SLOGAN']] = noduplicated_product['NAME'].str.split('[,-.]', 1, expand=True)\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\3431089402.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product[['PRODUCT', 'SLOGAN']] = noduplicated_product['NAME'].str.split('[,-.]', 1, expand=True)\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\3431089402.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product['PRODUCT'] = noduplicated_product['PRODUCT'].str.strip()\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\3431089402.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product['SLOGAN'] = noduplicated_product['SLOGAN'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "noduplicated_product['NAME'] = noduplicated_product['NAME'].str.replace(r'-(?=\\w)', '_')\n",
    "noduplicated_product[['PRODUCT', 'SLOGAN']] = noduplicated_product['NAME'].str.split('[,-.]', 1, expand=True)\n",
    "noduplicated_product['PRODUCT'] = noduplicated_product['PRODUCT'].str.strip()\n",
    "noduplicated_product['SLOGAN'] = noduplicated_product['SLOGAN'].str.strip()\n",
    "noduplicated_product.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar un visionado de los datos que tienen para discernir donde se puede realizar la separación.\n",
    "\n",
    "Por un lado extraeremos las características en una nueva columna, dejando la Description en la misma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\1090549632.py:1: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  noduplicated_product['CHARACTERISTICS'] = noduplicated_product['INFO'].str.split('Ver características y medidas|Características', 1).str[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 550 entries, 0 to 575\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               550 non-null    int64  \n",
      " 1   NAME             550 non-null    object \n",
      " 2   INFO             550 non-null    object \n",
      " 3   LISTA_URL        550 non-null    object \n",
      " 4   REGULAR_PRICE    550 non-null    float64\n",
      " 5   DISCOUNT_PRICE   550 non-null    float64\n",
      " 6   PRODUCT          550 non-null    object \n",
      " 7   SLOGAN           454 non-null    object \n",
      " 8   CHARACTERISTICS  489 non-null    object \n",
      " 9   DESCRIPTION      550 non-null    object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 47.3+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\1090549632.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product['CHARACTERISTICS'] = noduplicated_product['INFO'].str.split('Ver características y medidas|Características', 1).str[1]\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\1090549632.py:2: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  noduplicated_product['DESCRIPTION'] = noduplicated_product['INFO'].str.split('Ver características y medidas|Características', 1).str[0].str.strip()\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\1090549632.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product['DESCRIPTION'] = noduplicated_product['INFO'].str.split('Ver características y medidas|Características', 1).str[0].str.strip()\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\1090549632.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product['CHARACTERISTICS'] = noduplicated_product['CHARACTERISTICS'].str.replace('\\r', ' ')\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\1090549632.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product['DESCRIPTION'] = noduplicated_product['DESCRIPTION'].str.replace('\\r', ' ')\n"
     ]
    }
   ],
   "source": [
    "noduplicated_product['CHARACTERISTICS'] = noduplicated_product['INFO'].str.split('Ver características y medidas|Características', 1).str[1]\n",
    "noduplicated_product['DESCRIPTION'] = noduplicated_product['INFO'].str.split('Ver características y medidas|Características', 1).str[0].str.strip()\n",
    "noduplicated_product['CHARACTERISTICS'] = noduplicated_product['CHARACTERISTICS'].str.replace('\\r', ' ')\n",
    "noduplicated_product['DESCRIPTION'] = noduplicated_product['DESCRIPTION'].str.replace('\\r', ' ')\n",
    "noduplicated_product.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reestructuramos el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\2928903985.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product.drop(columns=['NAME'],inplace=True)\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\2928903985.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_product.drop(columns=['INFO'],inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>SLOGAN</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CHARACTERISTICS</th>\n",
       "      <th>LISTA_URL</th>\n",
       "      <th>REGULAR_PRICE</th>\n",
       "      <th>DISCOUNT_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Desliz! Lubricante íntimo de agua 100ml</td>\n",
       "      <td>None</td>\n",
       "      <td>Algunos lubricantes son un poco densos, otros ...</td>\n",
       "      <td>Bote de 100ml de venta exclusiva en amantis.ne...</td>\n",
       "      <td>https://www.amantis.net/desliz-lubricante-inti...</td>\n",
       "      <td>9.99</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TOBOGANE HOT RABBIT</td>\n",
       "      <td>el superventas de amantis ¡mejorado!</td>\n",
       "      <td>Vuelve nuestro vibrador de doble estimulación ...</td>\n",
       "      <td>Medidas: 19cm (11cm insertables) y 3,3cm/ 2,2c...</td>\n",
       "      <td>https://www.amantis.net/tobogane-hot-rabbit-el...</td>\n",
       "      <td>89.99</td>\n",
       "      <td>39.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BALLENATO</td>\n",
       "      <td>tu vibrador a distancia con aleta móvil y sume...</td>\n",
       "      <td>De las profundidades más húmedas llega BALLENA...</td>\n",
       "      <td>Mando a distancia.Peso 62 gramos.Silicona médi...</td>\n",
       "      <td>https://www.amantis.net/ballenato-tu-vibrador-...</td>\n",
       "      <td>99.99</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TANDEM 2 flex</td>\n",
       "      <td>vibrador doble flexible con mando</td>\n",
       "      <td>Tanto si ya eras fan de nuestro querido TANDEM...</td>\n",
       "      <td>10 patrones de vibración diferentes y tres niv...</td>\n",
       "      <td>https://www.amantis.net/tandem-2-flex-vibrador...</td>\n",
       "      <td>109.99</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FOXY</td>\n",
       "      <td>Succionador con mango vibrador y orejitas</td>\n",
       "      <td>Los succionadores van evolucionando, vamos des...</td>\n",
       "      <td>Vibrador con orejitas y succión simultáneaMate...</td>\n",
       "      <td>https://www.amantis.net/foxy-vibrador-succiona...</td>\n",
       "      <td>59.99</td>\n",
       "      <td>39.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                  PRODUCT  \\\n",
       "0   0  Desliz! Lubricante íntimo de agua 100ml   \n",
       "1   1                      TOBOGANE HOT RABBIT   \n",
       "2   2                                BALLENATO   \n",
       "3   3                            TANDEM 2 flex   \n",
       "4   4                                     FOXY   \n",
       "\n",
       "                                              SLOGAN  \\\n",
       "0                                               None   \n",
       "1               el superventas de amantis ¡mejorado!   \n",
       "2  tu vibrador a distancia con aleta móvil y sume...   \n",
       "3                  vibrador doble flexible con mando   \n",
       "4          Succionador con mango vibrador y orejitas   \n",
       "\n",
       "                                         DESCRIPTION  \\\n",
       "0  Algunos lubricantes son un poco densos, otros ...   \n",
       "1  Vuelve nuestro vibrador de doble estimulación ...   \n",
       "2  De las profundidades más húmedas llega BALLENA...   \n",
       "3  Tanto si ya eras fan de nuestro querido TANDEM...   \n",
       "4  Los succionadores van evolucionando, vamos des...   \n",
       "\n",
       "                                     CHARACTERISTICS  \\\n",
       "0  Bote de 100ml de venta exclusiva en amantis.ne...   \n",
       "1  Medidas: 19cm (11cm insertables) y 3,3cm/ 2,2c...   \n",
       "2  Mando a distancia.Peso 62 gramos.Silicona médi...   \n",
       "3  10 patrones de vibración diferentes y tres niv...   \n",
       "4  Vibrador con orejitas y succión simultáneaMate...   \n",
       "\n",
       "                                           LISTA_URL  REGULAR_PRICE  \\\n",
       "0  https://www.amantis.net/desliz-lubricante-inti...           9.99   \n",
       "1  https://www.amantis.net/tobogane-hot-rabbit-el...          89.99   \n",
       "2  https://www.amantis.net/ballenato-tu-vibrador-...          99.99   \n",
       "3  https://www.amantis.net/tandem-2-flex-vibrador...         109.99   \n",
       "4  https://www.amantis.net/foxy-vibrador-succiona...          59.99   \n",
       "\n",
       "   DISCOUNT_PRICE  \n",
       "0            7.99  \n",
       "1           39.99  \n",
       "2           49.99  \n",
       "3           49.99  \n",
       "4           39.99  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_1 = noduplicated_product.pop('PRODUCT')\n",
    "col_2=noduplicated_product.pop('SLOGAN')\n",
    "col_3=noduplicated_product.pop('DESCRIPTION')\n",
    "col_4=noduplicated_product.pop('CHARACTERISTICS')\n",
    "\n",
    "noduplicated_product.drop(columns=['NAME'],inplace=True)\n",
    "noduplicated_product.drop(columns=['INFO'],inplace=True)\n",
    "\n",
    "noduplicated_product.insert(loc= 1 , column= 'PRODUCT', value= col_1)\n",
    "noduplicated_product.insert(loc= 2 , column= 'SLOGAN', value= col_2)\n",
    "noduplicated_product.insert(loc= 3 , column= 'DESCRIPTION', value= col_3)\n",
    "noduplicated_product.insert(loc= 4 , column= 'CHARACTERISTICS', value= col_4)\n",
    "noduplicated_product.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertimos la feauture *DATE* de *COMENTARIOS*, que es de tipo string en *Datetime*.\n",
    "\n",
    "De la columna *DATE* extraigo los valores de *DAY*, *MONTH* y *YEAR*.\n",
    "\n",
    "Con la columna *MONTH* hago un mapeo para convertir en el número correspondiente del mes y así poder generar la nueva columna *DATE* con estos  datos.\n",
    "\n",
    "Convierto la columna *DATE* en datetime con los datos de las 3 últimas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Este es el diccionario para mapear los meses'''\n",
    "\n",
    "dm_mapping={\n",
    "    'enero':1, \n",
    "    'febrero':2, \n",
    "    'marzo':3, \n",
    "    'abril':4, \n",
    "    'mayo':5,\n",
    "    'junio':6, \n",
    "    'julio':7,\n",
    "    'agosto':8, \n",
    "    'septiembre':9, \n",
    "    'octubre':10, \n",
    "    'noviembre':11, \n",
    "    'diciembre':12,\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\930944462.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_comments['DAY']=noduplicated_comments['DATE'].str.split(' ').str.get(1).astype('Int64')\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\930944462.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_comments['MONTH']=noduplicated_comments['DATE'].str.split(' ').str.get(2).str.split(',').str.get(0)\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\930944462.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_comments['YEAR']=noduplicated_comments['DATE'].str.split(' ').str.get(-1).astype('Int64')\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\930944462.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_comments['MONTH']=noduplicated_comments['MONTH'].map(dm_mapping)\n",
      "C:\\Users\\Javier\\AppData\\Local\\Temp\\ipykernel_16032\\930944462.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  noduplicated_comments['DATE'] = pd.to_datetime(noduplicated_comments.iloc[:,-3:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>RATIO</th>\n",
       "      <th>USERS</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>5</td>\n",
       "      <td>David</td>\n",
       "      <td>Muy recomendable. El bote cunde, hidrata muy b...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>5</td>\n",
       "      <td>Ferran</td>\n",
       "      <td>Es la primera vez que compro este lubricante y...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>5</td>\n",
       "      <td>Sergio</td>\n",
       "      <td>He probado varios tipos de lubricante y este d...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>5</td>\n",
       "      <td>Jaime</td>\n",
       "      <td>Perfecto para embadurnarte el pincelin y meter...</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>5</td>\n",
       "      <td>YASMINA</td>\n",
       "      <td>Buen producto, tanto para el cuerpo a cuerpo c...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       DATE  RATIO    USERS  \\\n",
       "0   0 2023-05-18      5    David   \n",
       "1   0 2023-04-12      5   Ferran   \n",
       "2   0 2023-04-10      5   Sergio   \n",
       "3   0 2023-01-23      5    Jaime   \n",
       "4   0 2023-01-11      5  YASMINA   \n",
       "\n",
       "                                             COMMENT  DAY  MONTH  YEAR  \n",
       "0  Muy recomendable. El bote cunde, hidrata muy b...   18      5  2023  \n",
       "1  Es la primera vez que compro este lubricante y...   12      4  2023  \n",
       "2  He probado varios tipos de lubricante y este d...   10      4  2023  \n",
       "3  Perfecto para embadurnarte el pincelin y meter...   23      1  2023  \n",
       "4  Buen producto, tanto para el cuerpo a cuerpo c...   11      1  2023  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noduplicated_comments['DAY']=noduplicated_comments['DATE'].str.split(' ').str.get(1).astype('Int64')\n",
    "noduplicated_comments['MONTH']=noduplicated_comments['DATE'].str.split(' ').str.get(2).str.split(',').str.get(0)\n",
    "noduplicated_comments['YEAR']=noduplicated_comments['DATE'].str.split(' ').str.get(-1).astype('Int64')\n",
    "\n",
    "noduplicated_comments['MONTH']=noduplicated_comments['MONTH'].map(dm_mapping)\n",
    "noduplicated_comments['DATE'] = pd.to_datetime(noduplicated_comments.iloc[:,-3:])\n",
    "noduplicated_comments.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generamos ficheros .csv para ir guardando esta información antes de dejarlas salvadas en una BBDD Relacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noduplicated_product.to_csv('./Data/productos.csv',header=True,index=False)                       # Tengo que generar el path correcto\n",
    "noduplicated_comments.to_csv('./Data/comentarios_scrape.csv',header=True,index=True)           # Tengo que generar el path correcto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tratamiento de los datos de texto con RegEx y Librerías de NLP\n",
    "\n",
    "Primeramente vamos a generar nuevas columnas a partir de *Name* y *Description*. \n",
    "\n",
    "Estas columnas las generaremos a partir de *RegEx* y los métodos *str.split* y *str.replace*.\n",
    "\n",
    "Utilizaremos las siguientes librerías para el tratamiento  de la información."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afde6861a040563f15a2ec1b440faf84809f9a7bcc3c75cfd11a60e7dd448719"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
