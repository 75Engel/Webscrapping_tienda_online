{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Pero.... qué es el web scraping?\n",
    "\n",
    "En pocas palabras, el web scraping es la recopilación automatizada de datos de sitios web (para ser más precisos, del contenido HTML de los sitios web).\n",
    "\n",
    "En este Jupyter, aprenderás los conceptos básicos sobre cómo extraer datos de HTML. \n",
    "\n",
    "Lo harás extrayendo datos de la página de libros más vendidos de Book Depository, y para lograr esto, también tendrá que hacer uso de un poco de pandas principalmente.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conoce a tus nuevos mejores amigos: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beautiful Soup\n",
    "- Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la experiencia completa de Beautiful Soup, también deberás instalar un parser, dentro de ellos tenemos..\n",
    "\n",
    "- html.parser\n",
    "- lxml\n",
    "- html5lib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mi primer scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre lo primero es importar las librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora, estamos listos para solicitar nuestra primera página web. No es nada complicado: guardamos la URL que queremos raspar en la variable URL, luego solicitamos la URL (requests.get (url)) y guardamos la respuesta en la variable de respuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amantis.net/productos-amantis/\"              # lista productos\n",
    "url_principal=\"https://www.amantis.net/\"                        # productos\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo saber si se guardo correctamente el sitio web?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posibles respuestas:\n",
    "\n",
    "- [Respuestas informativas](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#information_responses) (100–199)\n",
    "- [Respuestas exitosas](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#successful_responses) (200–299)\n",
    "- [Mensajes de redirección](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#redirection_messages) (300–399)\n",
    "- [Respuestas de error del cliente](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#client_error_responses) (400–499)\n",
    "- [Respuestas de error del servidor](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses) (500–599)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero necesitamos el contenido HTML de la página web solicitada, así que como siguiente paso guardamos el contenido de la respuesta a html:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = response.content\n",
    "soup = bs(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aquí tienes una guía para cómo habilitarlo'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a.get_text()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener los datos de los productos (find_all + get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello vamos a inspeccionar en el navegador (click derecho sobre un titulo de un libro y elegimos inspeccionar)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este codigo extraigo la información de los productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"t2sDiv-titulo hidden text-left color-corporativo\">Top ventas en amantis</h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tobogane-hot-rabbit-el-superventas-amantis-mejorado/\">\n",
       " <span>TOBOGANE HOT RABBIT, el superventas de amantis ¡mejorado!</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/ballenato-tu-vibrador-distancia-aleta-movil-sumergible/\">\n",
       " <span>BALLENATO, tu vibrador a distancia con aleta móvil y sumergible...</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/meneo-sube-baja-realista-control-remoto/\">\n",
       " <span>MENEO sube y baja, placer realista con control remoto</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/foxtail-plug-anal-cola-zorro/\">\n",
       " <span>FOXTAIL, plug anal cola de zorro de 35cm</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/lizo-2-dildo-suave-silicona-3-tamanos/\">\n",
       " <span>LIZO 2, Dildo de suave silicona en 3 tamaños</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tobogane-el-vibrador-doble-mas-vendido-ahora-efecto-hot/\">\n",
       " <span>TOBOGANE, el vibrador doble más vendido</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/bacanal-monodosis-pack-10-uds/\">\n",
       " <span>Bacanal Gel Anal monodosis, Pack de 10 uds</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/desliz-vibragel-liquido-vibrador-30ml/\">\n",
       " <span>Vibrador Líquido con sabor Desliz! VIBRAGEL 30ml, hormigueo...</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/fresh-girl-6-kilos-40cm-piel-real-disfrutable/\">\n",
       " <span>FRESH GIRL, 6 Kilos y 40cm de piel real disfrutable</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/sazzia-vagina-hiperrealista-amantis/\">\n",
       " <span>SAZZIA, masturbador hiperrealista</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tandem-2-flex-vibrador-doble-flexible-mando/\">\n",
       " <span>TANDEM 2 flex, vibrador doble flexible con mando</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/cristalino-xl-gran-dildo-transparente-22cm/\">\n",
       " <span>CRISTALINO XL, gran dildo transparente de 22cm</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/floggy-flogger-bdsm-piel-vegana/\">\n",
       " <span>FLOGGY - Flogger BDSM de piel vegana</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/suabe-flogger-bdsm-pelo-sintetico-vegano/\">\n",
       " <span>SÜABE - Flogger BDSM de pelo sintético vegano</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/reggia-masturbador-masculino-doble/\">\n",
       " <span>REGGIA, masturbador masculino doble</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/pro-anal-2-vibrador-anal/\">\n",
       " <span>Pro ANAL, vibrador anal progresivo</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/trompi-vibrador-sumergible-ideal-punto-g/\">\n",
       " <span>TROMPI, vibrador sumergible ideal para Punto-G</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/kit-3-plugs-anales-diamante-black-star-plugress/\">\n",
       " <span>Kit de 3 Plugs anales con diamante BLACK STAR Plugress</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/power-up-meter-bomba-succion-manometro/\">\n",
       " <span>POWER UP METER - Bomba de succión con manómetro</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/dulce-tormento-pala-bambu-azotes/\">\n",
       " <span>DULCE TORMENTO, pala de bambú para azotes</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/cuore-trio-kit-3-plugs-corazon/\">\n",
       " <span>CUORE TRÍO, Kit de 3 plugs con corazón</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/magic-cup-6-masturbador-masculino/\">\n",
       " <span>MAGIC CUP, Masturbarse mola un huevo</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tris-anilla-vibrador-doble-penetracion-trinity/\">\n",
       " <span>TRIS-TRAS, anilla con vibrador para doble penetración TRINITY...</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/mastina-arnes-clasico-comodo/\">\n",
       " <span>MASTINA, un arnés clásico, cómodo y sencillo</span>\n",
       " </a>\n",
       " </h3>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_h3 = soup.find_all(\"h3\")\n",
    "all_h3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este codigo extraigo los precios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['39.99',\n",
       " '43.99',\n",
       " '44.99',\n",
       " '9.99',\n",
       " '17.99',\n",
       " '36.99',\n",
       " '9.99',\n",
       " '99.99',\n",
       " '29.99',\n",
       " '59.99',\n",
       " '17.99',\n",
       " '4.99',\n",
       " '14.99',\n",
       " '29.99',\n",
       " '34.99',\n",
       " '26.99',\n",
       " '24.99',\n",
       " '19.99',\n",
       " '9.99',\n",
       " '24.99',\n",
       " '9.99',\n",
       " '24.99',\n",
       " '17.99']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_price=soup.find_all(\"span\",class_=\"productSpecialPrice\")\n",
    "price=[]\n",
    "\n",
    "for precio in all_price:\n",
    "    item_price=precio.get_text(strip=True).replace(\",\", \".\").split('€')[0]\n",
    "    price.append(item_price)\n",
    "price\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este codigo extraigo la información de los nombres de los productos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda pendiente evitar que name y demás variables sean listas de listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TOBOGANE HOT RABBIT', 'BALLENATO', 'MENEO sube y baja', 'FOXTAIL', 'LIZO 2', 'TOBOGANE', 'Bacanal Gel Anal monodosis', 'Vibrador Líquido con sabor Desliz! VIBRAGEL 30ml', 'FRESH GIRL', 'SAZZIA', 'TANDEM 2 flex', 'CRISTALINO XL', 'FLOGGY - Flogger BDSM de piel vegana', 'SÜABE - Flogger BDSM de pelo sintético vegano', 'REGGIA', 'Pro ANAL', 'TROMPI', 'Kit de 3 Plugs anales con diamante BLACK STAR Plugress', 'POWER UP METER - Bomba de succión con manómetro', 'DULCE TORMENTO', 'CUORE TRÍO', 'MAGIC CUP', 'TRIS-TRAS', 'MASTINA']\n"
     ]
    }
   ],
   "source": [
    "titulos=soup.find_all(\"h3\")\n",
    "name=[]\n",
    "desc=[]\n",
    "for titulo in titulos[1:]:\n",
    "    nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "    # description=titulo.get_text(strip=True).split(',')[1]\n",
    "    name.append(nombre)\n",
    "    # desc.append(description)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"t2sDiv-titulo hidden text-left color-corporativo\">Top ventas en amantis</h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tobogane-hot-rabbit-el-superventas-amantis-mejorado/\">\n",
       " <span>TOBOGANE HOT RABBIT, el superventas de amantis ¡mejorado!</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/ballenato-tu-vibrador-distancia-aleta-movil-sumergible/\">\n",
       " <span>BALLENATO, tu vibrador a distancia con aleta móvil y sumergible...</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/meneo-sube-baja-realista-control-remoto/\">\n",
       " <span>MENEO sube y baja, placer realista con control remoto</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/foxtail-plug-anal-cola-zorro/\">\n",
       " <span>FOXTAIL, plug anal cola de zorro de 35cm</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/lizo-2-dildo-suave-silicona-3-tamanos/\">\n",
       " <span>LIZO 2, Dildo de suave silicona en 3 tamaños</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tobogane-el-vibrador-doble-mas-vendido-ahora-efecto-hot/\">\n",
       " <span>TOBOGANE, el vibrador doble más vendido</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/bacanal-monodosis-pack-10-uds/\">\n",
       " <span>Bacanal Gel Anal monodosis, Pack de 10 uds</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/desliz-vibragel-liquido-vibrador-30ml/\">\n",
       " <span>Vibrador Líquido con sabor Desliz! VIBRAGEL 30ml, hormigueo...</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/fresh-girl-6-kilos-40cm-piel-real-disfrutable/\">\n",
       " <span>FRESH GIRL, 6 Kilos y 40cm de piel real disfrutable</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/sazzia-vagina-hiperrealista-amantis/\">\n",
       " <span>SAZZIA, masturbador hiperrealista</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tandem-2-flex-vibrador-doble-flexible-mando/\">\n",
       " <span>TANDEM 2 flex, vibrador doble flexible con mando</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/cristalino-xl-gran-dildo-transparente-22cm/\">\n",
       " <span>CRISTALINO XL, gran dildo transparente de 22cm</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/floggy-flogger-bdsm-piel-vegana/\">\n",
       " <span>FLOGGY - Flogger BDSM de piel vegana</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/suabe-flogger-bdsm-pelo-sintetico-vegano/\">\n",
       " <span>SÜABE - Flogger BDSM de pelo sintético vegano</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/reggia-masturbador-masculino-doble/\">\n",
       " <span>REGGIA, masturbador masculino doble</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/pro-anal-2-vibrador-anal/\">\n",
       " <span>Pro ANAL, vibrador anal progresivo</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/trompi-vibrador-sumergible-ideal-punto-g/\">\n",
       " <span>TROMPI, vibrador sumergible ideal para Punto-G</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/kit-3-plugs-anales-diamante-black-star-plugress/\">\n",
       " <span>Kit de 3 Plugs anales con diamante BLACK STAR Plugress</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/power-up-meter-bomba-succion-manometro/\">\n",
       " <span>POWER UP METER - Bomba de succión con manómetro</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/dulce-tormento-pala-bambu-azotes/\">\n",
       " <span>DULCE TORMENTO, pala de bambú para azotes</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/cuore-trio-kit-3-plugs-corazon/\">\n",
       " <span>CUORE TRÍO, Kit de 3 plugs con corazón</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/magic-cup-6-masturbador-masculino/\">\n",
       " <span>MAGIC CUP, Masturbarse mola un huevo</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tris-anilla-vibrador-doble-penetracion-trinity/\">\n",
       " <span>TRIS-TRAS, anilla con vibrador para doble penetración TRINITY...</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/mastina-arnes-clasico-comodo/\">\n",
       " <span>MASTINA, un arnés clásico, cómodo y sencillo</span>\n",
       " </a>\n",
       " </h3>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"h3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TOBOGANE HOT RABBIT',\n",
       " 'BALLENATO',\n",
       " 'MENEO sube y baja',\n",
       " 'FOXTAIL',\n",
       " 'LIZO 2',\n",
       " 'TOBOGANE',\n",
       " 'Bacanal Gel Anal monodosis',\n",
       " 'Vibrador Líquido con sabor Desliz! VIBRAGEL 30ml',\n",
       " 'FRESH GIRL',\n",
       " 'SAZZIA',\n",
       " 'TANDEM 2 flex',\n",
       " 'CRISTALINO XL',\n",
       " 'FLOGGY - Flogger BDSM de piel vegana',\n",
       " 'SÜABE - Flogger BDSM de pelo sintético vegano',\n",
       " 'REGGIA',\n",
       " 'Pro ANAL',\n",
       " 'TROMPI',\n",
       " 'Kit de 3 Plugs anales con diamante BLACK STAR Plugress',\n",
       " 'POWER UP METER - Bomba de succión con manómetro',\n",
       " 'DULCE TORMENTO',\n",
       " 'CUORE TRÍO',\n",
       " 'MAGIC CUP',\n",
       " 'TRIS-TRAS',\n",
       " 'MASTINA']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este codigo extraigo la descripción del producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['el superventas de amantis ¡mejorado!'], ['tu vibrador a distancia con aleta móvil y sumergible...'], ['placer realista con control remoto'], ['plug anal cola de zorro de 35cm'], ['Dildo de suave silicona en 3 tamaños'], ['el vibrador doble más vendido'], ['Pack de 10 uds'], ['hormigueo...'], ['6 Kilos y 40cm de piel real disfrutable'], ['masturbador hiperrealista'], ['vibrador doble flexible con mando'], ['gran dildo transparente de 22cm'], ['No hay datos'], ['No hay datos'], ['masturbador masculino doble'], ['vibrador anal progresivo'], ['vibrador sumergible ideal para Punto-G'], ['No hay datos'], ['No hay datos'], ['pala de bambú para azotes'], ['Kit de 3 plugs con corazón'], ['Masturbarse mola un huevo'], ['anilla con vibrador para doble penetración TRINITY...'], ['un arnés clásico', 'cómodo y sencillo']]\n"
     ]
    }
   ],
   "source": [
    "titulos=soup.find_all(\"h3\")\n",
    "desc=[]\n",
    "\n",
    "for titulo in titulos[1:]:\n",
    "    description=titulo.get_text(strip=True).split(', ')[1:]\n",
    "    if description==[]:\n",
    "        description=[\"No hay datos\"]\n",
    "    desc.append(description)\n",
    "\n",
    "print(desc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto extraigo los links de los productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productos = soup.find_all(class_='caption')\n",
    "lista_URLs = []\n",
    "for producto in productos[8:]:\n",
    "    URL_producto = producto.find('a')['href']\n",
    "    lista_URLs.append(URL_producto)\n",
    "\n",
    "len(lista_URLs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta parte del codigo intento extraer la información de los comentarios??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hearts = soup.find_all(\"h3\",class_=\"col_xs_12\")\n",
    "# # hearts\n",
    "# for heart in hearts:\n",
    "#        print(heart.get_text())\n",
    "# # print(len(all_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hearts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quedaría entrar en cada link para extraer la información de los comentarios de cada producto, número de comentarios por ejemplo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el codigo completo para extraer la información de cada página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Realidad Virtual 2</td>\n",
       "      <td>[tacto real + rotación + vibración]</td>\n",
       "      <td>37.99</td>\n",
       "      <td>https://www.amantis.net/realidad-virtual-2-tac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERGO-G de amantis</td>\n",
       "      <td>[con 3 motores y recargable ¡tiembla Punto...]</td>\n",
       "      <td>74.99</td>\n",
       "      <td>https://www.amantis.net/ergo-g-amantis-3-motor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr BUFF recargable</td>\n",
       "      <td>[1 vibrador en cada oreja! éxtasis en estéreo...]</td>\n",
       "      <td>49.99</td>\n",
       "      <td>https://www.amantis.net/mr-buff-recargable-1-v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seda•G de amantis</td>\n",
       "      <td>[doble estimulación de sedosa silicona]</td>\n",
       "      <td>24.99</td>\n",
       "      <td>https://www.amantis.net/seda-g-amantis-doble-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAZONE PELOUSSE - Azotes y Caricias</td>\n",
       "      <td>[No hay datos]</td>\n",
       "      <td>9.99</td>\n",
       "      <td>https://www.amantis.net/amazone-pelousse-azote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Azótame Corazón</td>\n",
       "      <td>[paleta de polipiel color rosa o negro]</td>\n",
       "      <td>5.99</td>\n",
       "      <td>https://www.amantis.net/azotame-corazon-paleta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pendientes para pezones con aros</td>\n",
       "      <td>[estimulación garantizada]</td>\n",
       "      <td>6.99</td>\n",
       "      <td>https://www.amantis.net/pendientes-pezones-aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pluma para caricias eróticas con aplicador</td>\n",
       "      <td>[No hay datos]</td>\n",
       "      <td>4.99</td>\n",
       "      <td>https://www.amantis.net/pluma-caricias-erotica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cuerdita con plumas para caricias eróticas</td>\n",
       "      <td>[No hay datos]</td>\n",
       "      <td>3.99</td>\n",
       "      <td>https://www.amantis.net/cuerdita-plumas-carici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kit de inmovilización de amantis Hogtie-Fácil</td>\n",
       "      <td>[No hay datos]</td>\n",
       "      <td>21.99</td>\n",
       "      <td>https://www.amantis.net/kit-inmovilizacion-ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Estimulador prostático</td>\n",
       "      <td>[ahora más potente]</td>\n",
       "      <td>19.99</td>\n",
       "      <td>https://www.amantis.net/estimulador-prostatico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Los 5 sentidos</td>\n",
       "      <td>[Kit de bondage de 5 piezas]</td>\n",
       "      <td>17.99</td>\n",
       "      <td>https://www.amantis.net/los-5-sentidos-kit-bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Realidad Virtual®Liquid Shots</td>\n",
       "      <td>[eyacula de verdad]</td>\n",
       "      <td>23.99</td>\n",
       "      <td>https://www.amantis.net/realidad-virtual-liqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Glup! Dildo CLITO de silicona</td>\n",
       "      <td>[dos tamaños y con ventosa]</td>\n",
       "      <td>21.99</td>\n",
       "      <td>https://www.amantis.net/glup-dildo-clito-silic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MATADOR NATURAL</td>\n",
       "      <td>[Dildo realista en silicona-platino con ventos...</td>\n",
       "      <td>54.99</td>\n",
       "      <td>https://www.amantis.net/matador-natural-dildo-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Esposas de cuero</td>\n",
       "      <td>[inmovilízame para llegar lejos]</td>\n",
       "      <td>9.99</td>\n",
       "      <td>https://www.amantis.net/esposas-cuero-inmovili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MAJETE</td>\n",
       "      <td>[Dildo realista y generoso con ventosa]</td>\n",
       "      <td>24.99</td>\n",
       "      <td>https://www.amantis.net/majete-dildo-realista-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AZZOTE</td>\n",
       "      <td>[Azotador con suaves tiras de ante]</td>\n",
       "      <td>17.99</td>\n",
       "      <td>https://www.amantis.net/azzote-azotador-suaves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Azotador ligero de polipiel de 50cm</td>\n",
       "      <td>[No hay datos]</td>\n",
       "      <td>5.99</td>\n",
       "      <td>https://www.amantis.net/azotador-ligero-polipi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mantente-firme</td>\n",
       "      <td>[potente anilla DOBLE INFINITO]</td>\n",
       "      <td>6.99</td>\n",
       "      <td>https://www.amantis.net/mantente-firme-potente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Realidad Virtual 360®</td>\n",
       "      <td>[con mando a distancia y recargable]</td>\n",
       "      <td>49.99</td>\n",
       "      <td>https://www.amantis.net/realidad-virtual-360-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BRUCE 20cm</td>\n",
       "      <td>[Dildo realista de silicona platino con ventosa]</td>\n",
       "      <td>39.99</td>\n",
       "      <td>https://www.amantis.net/bruce-20cm-dildo-reali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HAFTHOR 21cm</td>\n",
       "      <td>[Gran dildo de silicona platino con ventosa]</td>\n",
       "      <td>44.99</td>\n",
       "      <td>https://www.amantis.net/hafthor-21cm-gran-dild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AVATAR ALIEN</td>\n",
       "      <td>[amante texturizado de suave silicona]</td>\n",
       "      <td>24.99</td>\n",
       "      <td>https://www.amantis.net/avatar-alien-amante-te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                              Realidad Virtual 2   \n",
       "1                               ERGO-G de amantis   \n",
       "2                              Mr BUFF recargable   \n",
       "3                               Seda•G de amantis   \n",
       "4            AMAZONE PELOUSSE - Azotes y Caricias   \n",
       "5                                 Azótame Corazón   \n",
       "6                Pendientes para pezones con aros   \n",
       "7      Pluma para caricias eróticas con aplicador   \n",
       "8      Cuerdita con plumas para caricias eróticas   \n",
       "9   Kit de inmovilización de amantis Hogtie-Fácil   \n",
       "10                         Estimulador prostático   \n",
       "11                                 Los 5 sentidos   \n",
       "12                  Realidad Virtual®Liquid Shots   \n",
       "13                  Glup! Dildo CLITO de silicona   \n",
       "14                                MATADOR NATURAL   \n",
       "15                               Esposas de cuero   \n",
       "16                                         MAJETE   \n",
       "17                                         AZZOTE   \n",
       "18            Azotador ligero de polipiel de 50cm   \n",
       "19                                 Mantente-firme   \n",
       "20                          Realidad Virtual 360®   \n",
       "21                                     BRUCE 20cm   \n",
       "22                                   HAFTHOR 21cm   \n",
       "23                                   AVATAR ALIEN   \n",
       "\n",
       "                                          Description  Price  \\\n",
       "0                 [tacto real + rotación + vibración]  37.99   \n",
       "1      [con 3 motores y recargable ¡tiembla Punto...]  74.99   \n",
       "2   [1 vibrador en cada oreja! éxtasis en estéreo...]  49.99   \n",
       "3             [doble estimulación de sedosa silicona]  24.99   \n",
       "4                                      [No hay datos]   9.99   \n",
       "5             [paleta de polipiel color rosa o negro]   5.99   \n",
       "6                          [estimulación garantizada]   6.99   \n",
       "7                                      [No hay datos]   4.99   \n",
       "8                                      [No hay datos]   3.99   \n",
       "9                                      [No hay datos]  21.99   \n",
       "10                                [ahora más potente]  19.99   \n",
       "11                       [Kit de bondage de 5 piezas]  17.99   \n",
       "12                                [eyacula de verdad]  23.99   \n",
       "13                        [dos tamaños y con ventosa]  21.99   \n",
       "14  [Dildo realista en silicona-platino con ventos...  54.99   \n",
       "15                   [inmovilízame para llegar lejos]   9.99   \n",
       "16            [Dildo realista y generoso con ventosa]  24.99   \n",
       "17                [Azotador con suaves tiras de ante]  17.99   \n",
       "18                                     [No hay datos]   5.99   \n",
       "19                    [potente anilla DOBLE INFINITO]   6.99   \n",
       "20               [con mando a distancia y recargable]  49.99   \n",
       "21   [Dildo realista de silicona platino con ventosa]  39.99   \n",
       "22       [Gran dildo de silicona platino con ventosa]  44.99   \n",
       "23             [amante texturizado de suave silicona]  24.99   \n",
       "\n",
       "                                                 link  \n",
       "0   https://www.amantis.net/realidad-virtual-2-tac...  \n",
       "1   https://www.amantis.net/ergo-g-amantis-3-motor...  \n",
       "2   https://www.amantis.net/mr-buff-recargable-1-v...  \n",
       "3   https://www.amantis.net/seda-g-amantis-doble-e...  \n",
       "4   https://www.amantis.net/amazone-pelousse-azote...  \n",
       "5   https://www.amantis.net/azotame-corazon-paleta...  \n",
       "6   https://www.amantis.net/pendientes-pezones-aro...  \n",
       "7   https://www.amantis.net/pluma-caricias-erotica...  \n",
       "8   https://www.amantis.net/cuerdita-plumas-carici...  \n",
       "9   https://www.amantis.net/kit-inmovilizacion-ama...  \n",
       "10  https://www.amantis.net/estimulador-prostatico...  \n",
       "11  https://www.amantis.net/los-5-sentidos-kit-bon...  \n",
       "12  https://www.amantis.net/realidad-virtual-liqui...  \n",
       "13  https://www.amantis.net/glup-dildo-clito-silic...  \n",
       "14  https://www.amantis.net/matador-natural-dildo-...  \n",
       "15  https://www.amantis.net/esposas-cuero-inmovili...  \n",
       "16  https://www.amantis.net/majete-dildo-realista-...  \n",
       "17  https://www.amantis.net/azzote-azotador-suaves...  \n",
       "18  https://www.amantis.net/azotador-ligero-polipi...  \n",
       "19  https://www.amantis.net/mantente-firme-potente...  \n",
       "20  https://www.amantis.net/realidad-virtual-360-m...  \n",
       "21  https://www.amantis.net/bruce-20cm-dildo-reali...  \n",
       "22  https://www.amantis.net/hafthor-21cm-gran-dild...  \n",
       "23  https://www.amantis.net/avatar-alien-amante-te...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos=soup.find_all(\"h3\")\n",
    "name=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "lista_URLs = []\n",
    "\n",
    "for titulo in titulos:\n",
    "    nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "    name.append(nombre)\n",
    "    description=titulo.get_text(strip=True).split(', ')[1:]\n",
    "    if description==[]:\n",
    "        description=[\"No hay datos\"]\n",
    "    desc.append(description)\n",
    "\n",
    "all_price=soup.find_all(\"span\",class_=\"productSpecialPrice\")\n",
    "\n",
    "for precio in all_price:\n",
    "    item_price=precio.get_text(strip=True).replace(\",\", \".\").split('€')[0]\n",
    "    price.append(item_price)\n",
    "\n",
    "productos = soup.find_all(class_='caption')\n",
    "for producto in productos[8:]:\n",
    "    URL_producto = producto.find('a')['href']\n",
    "    lista_URLs.append(URL_producto)\n",
    "\n",
    "df_productos = pd.DataFrame({\"Name\": name,\"Description\": desc,\"Price\":price,\"link\":lista_URLs})\n",
    "df_productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres: 24\n",
      "descrip: 24\n",
      "precio: 24\n",
      "URL: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombres:\" ,len(name))\n",
    "print(\"descrip:\" ,len(desc))\n",
    "print(\"precio:\" ,len(price))\n",
    "print(\"URL:\" ,len(lista_URLs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Realidad Virtual 2'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.amantis.net/realidad-virtual-2-tacto-real-rotacion-vibracion/'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_URLs[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_productos = pd.DataFrame({\"Name\": name,\"Description\": desc,\"Price\":price,\"link\":lista_URLs})\n",
    "# len(df_productos)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a sacar la información de todas las páginas posibles, para extraer los links de los productos y ver si podemos sacar la información de su página concreta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.amantis.net/realidad-virtual-2-tacto-real-rotacion-vibracion/'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_URLs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un nuevo request para el primer libro: \n",
    "r = requests.get(lista_URLs[0])\n",
    "\n",
    "# Creamos una sopa específica con la info de cada libro\n",
    "soup_producto = bs(r.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realidad Virtual 2, tacto real + rotación + vibración\n"
     ]
    }
   ],
   "source": [
    "name = soup_producto.find('h1').text\n",
    "print(name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta parte del código obtengo la información desde la página 1 en adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mtype\u001b[39m(pages[\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pages' is not defined"
     ]
    }
   ],
   "source": [
    "# type(pages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3 class=\"t2sDiv-titulo hidden text-left color-corporativo\">Top ventas en amantis</h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tobogane-hot-rabbit-el-superventas-amantis-mejorado/\">\n",
       " <span>TOBOGANE HOT RABBIT, el superventas de amantis ¡mejorado!</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/meneo-sube-baja-realista-control-remoto/\">\n",
       " <span>MENEO sube y baja, placer realista con control remoto</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/ballenato-tu-vibrador-distancia-aleta-movil-sumergible/\">\n",
       " <span>BALLENATO, tu vibrador a distancia con aleta móvil y sumergible...</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/squizze-vibrador-multiple-squirting/\">\n",
       " <span>SQUIZZE - Vibrador múltiple ideal para Squirting</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/tandem-2-flex-vibrador-doble-flexible-mando/\">\n",
       " <span>TANDEM 2 flex, vibrador doble flexible con mando</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/sazzia-vagina-hiperrealista-amantis/\">\n",
       " <span>SAZZIA, masturbador hiperrealista</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/reggia-masturbador-masculino-doble/\">\n",
       " <span>REGGIA, masturbador masculino doble</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/poseidon-vibrador-punto-g-triple-estimulacion/\">\n",
       " <span>POSEIDON - Vibrador punto G con triple estimulación</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/fresh-girl-6-kilos-40cm-piel-real-disfrutable/\">\n",
       " <span>FRESH GIRL, 6 Kilos y 40cm de piel real disfrutable</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/intensse-hot-rabbit-vibrador-estriado/\">\n",
       " <span>INTENSSE HOT RABBIT - Vibrador estriado</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/cunni-simulador-sexo-oral-vibracion/\">\n",
       " <span>CUNNI - Simulador de sexo oral con vibración</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/foxtail-plug-anal-cola-zorro/\">\n",
       " <span>FOXTAIL, plug anal cola de zorro de 35cm</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/amador-fucking-machine/\">\n",
       " <span>AMADOR - FUCKING MACHINE</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/lizo-2-dildo-suave-silicona-3-tamanos/\">\n",
       " <span>LIZO 2, Dildo de suave silicona en 3 tamaños</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/suabe-flogger-bdsm-pelo-sintetico-vegano/\">\n",
       " <span>SÜABE - Flogger BDSM de pelo sintético vegano</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/good-boy-intense-vibrador-efecto-calor-dos-tamanos/\">\n",
       " <span>GOOD BOY intense, vibrador con efecto calor en dos tamaños</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/swan-vibrador-succion-sonica/\">\n",
       " <span>SWAN - Vibrador con succión sónica</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/bisou-besos-ondas-succion-la-mejor-vibracion/\">\n",
       " <span>BISOU, besos por ondas de succión con la mejor vibración</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/miru-falda-abierta-desmontable/\">\n",
       " <span>MIRU - Falda fetish con vistas a tu trasero</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/idyllic-boy-grosso-plug-anal-distancia-mas-intenso/\">\n",
       " <span>IDYLLIC BOY, Plug anal a distancia más intenso</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/triple-rabbit-conejito-vibrador-bolas-anales/\">\n",
       " <span>TRIPLE RABBIT, Conejito vibrador con bolas anales</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/nina-vibrador-distancia-braguitas/\">\n",
       " <span>NINA - Vibrador a distancia con braguitas</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/trompi-vibrador-sumergible-ideal-punto-g/\">\n",
       " <span>TROMPI, vibrador sumergible ideal para Punto-G</span>\n",
       " </a>\n",
       " </h3>,\n",
       " <h3 class=\"h3 group inner list-group-item-heading tdd_listado_nombre\">\n",
       " <a href=\"https://www.amantis.net/kit-3-plugs-anales-diamante-black-star-plugress/\">\n",
       " <span>Kit de 3 Plugs anales con diamante BLACK STAR Plugress</span>\n",
       " </a>\n",
       " </h3>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=3\n",
    "url = \"https://www.amantis.net/productos-amantis/\"              # lista productos\n",
    "URL = url+'page' + str(page)+'/'\n",
    "response = requests.get(URL)\n",
    "titulos=soup.find_all(\"h3\")\n",
    "titulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.amantis.net/productos-amantis/page3/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL                             # Esto está mal, por esto no coge bien los datos de los links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = response.content\n",
    "soup = bs(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina 1\n",
      "Top ventas en amantis\n",
      "TOBOGANE HOT RABBIT\n",
      "BALLENATO\n",
      "MENEO sube y baja\n",
      "FOXTAIL\n",
      "LIZO 2\n",
      "TOBOGANE\n",
      "Bacanal Gel Anal monodosis\n",
      "Vibrador Líquido con sabor Desliz! VIBRAGEL 30ml\n",
      "FRESH GIRL\n",
      "SAZZIA\n",
      "TANDEM 2 flex\n",
      "CRISTALINO XL\n",
      "FLOGGY - Flogger BDSM de piel vegana\n",
      "SÜABE - Flogger BDSM de pelo sintético vegano\n",
      "REGGIA\n",
      "Pro ANAL\n",
      "TROMPI\n",
      "Kit de 3 Plugs anales con diamante BLACK STAR Plugress\n",
      "POWER UP METER - Bomba de succión con manómetro\n",
      "DULCE TORMENTO\n",
      "CUORE TRÍO\n",
      "MAGIC CUP\n",
      "TRIS-TRAS\n",
      "MASTINA\n",
      "https://www.amantis.net/tobogane-hot-rabbit-el-superventas-amantis-mejorado/\n",
      "https://www.amantis.net/ballenato-tu-vibrador-distancia-aleta-movil-sumergible/\n",
      "https://www.amantis.net/meneo-sube-baja-realista-control-remoto/\n",
      "https://www.amantis.net/foxtail-plug-anal-cola-zorro/\n",
      "https://www.amantis.net/lizo-2-dildo-suave-silicona-3-tamanos/\n",
      "https://www.amantis.net/tobogane-el-vibrador-doble-mas-vendido-ahora-efecto-hot/\n",
      "https://www.amantis.net/bacanal-monodosis-pack-10-uds/\n",
      "https://www.amantis.net/desliz-vibragel-liquido-vibrador-30ml/\n",
      "https://www.amantis.net/fresh-girl-6-kilos-40cm-piel-real-disfrutable/\n",
      "https://www.amantis.net/sazzia-vagina-hiperrealista-amantis/\n",
      "https://www.amantis.net/tandem-2-flex-vibrador-doble-flexible-mando/\n",
      "https://www.amantis.net/cristalino-xl-gran-dildo-transparente-22cm/\n",
      "https://www.amantis.net/floggy-flogger-bdsm-piel-vegana/\n",
      "https://www.amantis.net/suabe-flogger-bdsm-pelo-sintetico-vegano/\n",
      "https://www.amantis.net/reggia-masturbador-masculino-doble/\n",
      "https://www.amantis.net/pro-anal-2-vibrador-anal/\n",
      "https://www.amantis.net/trompi-vibrador-sumergible-ideal-punto-g/\n",
      "https://www.amantis.net/kit-3-plugs-anales-diamante-black-star-plugress/\n",
      "https://www.amantis.net/power-up-meter-bomba-succion-manometro/\n",
      "https://www.amantis.net/dulce-tormento-pala-bambu-azotes/\n",
      "https://www.amantis.net/cuore-trio-kit-3-plugs-corazon/\n",
      "https://www.amantis.net/magic-cup-6-masturbador-masculino/\n",
      "https://www.amantis.net/tris-anilla-vibrador-doble-penetracion-trinity/\n",
      "https://www.amantis.net/mastina-arnes-clasico-comodo/\n",
      "Pagina 2\n",
      "MASTINA\n",
      "MOMO - Boxer con rejillas laterales\n",
      "Kit de iniciación anal\n",
      "MAGIC CUP\n",
      "EXPLORE PERFECT\n",
      "TRIPLE RABBIT\n",
      "GOOD BOY intense\n",
      "TRIS-TRAS\n",
      "INTENSSE HOT RABBIT - Vibrador estriado\n",
      "MAGARAC\n",
      "Vibrador Líquido con sabor Desliz! VIBRAGEL 10ml\n",
      "Desliz! Anal monodosis\n",
      "VULVANIC\n",
      "AVATAR FIRST LOVER\n",
      "TOK2 bala vibradora con mando\n",
      "CAMILLE\n",
      "PASSION PUMP\n",
      "MIRU - Falda fetish con vistas a tu trasero\n",
      "IDYLLIC BOY\n",
      "PASSION CUP\n",
      "CUNNI - Simulador de sexo oral con vibración\n",
      "SQUIZZE - Vibrador múltiple ideal para Squirting\n",
      "COCÓ\n",
      "AMAZONA ECLIPSE\n",
      "https://www.amantis.net/mastina-arnes-clasico-comodo/\n",
      "https://www.amantis.net/momo-boxer-rejillas-laterales/\n",
      "https://www.amantis.net/kit-iniciacion-anal-tres-plugs-principantes/\n",
      "https://www.amantis.net/magic-cup-6-masturbador-masculino/\n",
      "https://www.amantis.net/explore-perfect-pene-realista-perfecto/\n",
      "https://www.amantis.net/triple-rabbit-conejito-vibrador-bolas-anales/\n",
      "https://www.amantis.net/good-boy-intense-vibrador-efecto-calor-dos-tamanos/\n",
      "https://www.amantis.net/tris-anilla-vibrador-doble-penetracion-trinity/\n",
      "https://www.amantis.net/intensse-hot-rabbit-vibrador-estriado/\n",
      "https://www.amantis.net/magarac-kit-arnes-esposas-by-amantis/\n",
      "https://www.amantis.net/desliz-vibragel-liquido-vibrador-10ml/\n",
      "https://www.amantis.net/desliz-anal-monodosis-pack-10-uds/\n",
      "https://www.amantis.net/vulvanic-vibrador-distancia-ergonomico-entraras-erupcion/\n",
      "https://www.amantis.net/avatar-first-lover-amante-realista-suave-silicona/\n",
      "https://www.amantis.net/tok2-bala-vibradora-mando-mas-potente-recargable/\n",
      "https://www.amantis.net/camille-body-camiseta-floral-cuello-halter-amantis/\n",
      "https://www.amantis.net/passion-pump-bomba-succion-automatica-amantis/\n",
      "https://www.amantis.net/miru-falda-abierta-desmontable/\n",
      "https://www.amantis.net/idyllic-boy-grosso-plug-anal-distancia-mas-intenso/\n",
      "https://www.amantis.net/passion-cup-manga-masturbadora-formas-realistas/\n",
      "https://www.amantis.net/cunni-simulador-sexo-oral-vibracion/\n",
      "https://www.amantis.net/squizze-vibrador-multiple-squirting/\n",
      "https://www.amantis.net/coco-body-tirantes-orificio-estrategico-amantis/\n",
      "https://www.amantis.net/amazona-vestido-sexy-cabalgadas/\n",
      "Pagina 3\n",
      "AMADOR - FUCKING MACHINE\n",
      "AMAZONA ECLIPSE\n",
      "EISSELY\n",
      "SQUIZZE - Vibrador múltiple ideal para Squirting\n",
      "Átame-Fácil\n",
      "COCÓ\n",
      "ALAS LIRIO\n",
      "YANTA\n",
      "BUTTERFLY\n",
      "TOK anal 10\n",
      "ATOMIC\n",
      "ORGASMATRÓN craneal\n",
      "Bacanal FORTE\n",
      "LINEAS INFINITAS\n",
      "DIGIT PRO\n",
      "BUDDY - Vibrador masturbador masculino suave\n",
      "DADOS AMANTIS\n",
      "MYSTERY\n",
      "SUTYEN\n",
      "MADNESS\n",
      "MANOMBA Cresci\n",
      "EXPLORE MUSCLE\n",
      "DOBLE DILDO REAL\n",
      "LAZZO\n",
      "https://www.amantis.net/amador-fucking-machine/\n",
      "https://www.amantis.net/amazona-vestido-sexy-cabalgadas/\n",
      "https://www.amantis.net/eissely-medias-abiertas-recorrer/\n",
      "https://www.amantis.net/squizze-vibrador-multiple-squirting/\n",
      "https://www.amantis.net/atame-facil-kit-cama-universal-amantis/\n",
      "https://www.amantis.net/coco-body-tirantes-orificio-estrategico-amantis/\n",
      "https://www.amantis.net/alas-medias-sexis-sin-liguero/\n",
      "https://www.amantis.net/yanta-anilla-doble-pene/\n",
      "https://www.amantis.net/butterfly-bodysocking-fina-malla-detalle-floral/\n",
      "https://www.amantis.net/tok-anal-10-vibrador-anal-10-modos-vibracion/\n",
      "https://www.amantis.net/atomic-impulsor-placer-by-amantis/\n",
      "https://www.amantis.net/orgasmatron-craneal-orgasmos-la-cabeza-los-pies/\n",
      "https://www.amantis.net/bacanal-forte-lubricante-anal-concentrado-aloe/\n",
      "https://www.amantis.net/lineas-infinitas-medias-liguero-piernas-infarto/\n",
      "https://www.amantis.net/digit-pro-dedal-vibrador-by-amantis/\n",
      "https://www.amantis.net/buddy-masturbador-masculino/\n",
      "https://www.amantis.net/dados-amantis-jugar-nunca-fue-tan-divertido/\n",
      "https://www.amantis.net/mystery-body-rejilla-super-sexy/\n",
      "https://www.amantis.net/sutyen-body-encaje-floral-efecto-liguero/\n",
      "https://www.amantis.net/madness-conjunto-malla-amantis/\n",
      "https://www.amantis.net/manomba-bomba-succion-manual-amantis/\n",
      "https://www.amantis.net/explore-muscle-pene-realista-poderoso/\n",
      "https://www.amantis.net/super-doble-dildo-real-una-experiencia-doble-45-cm/\n",
      "https://www.amantis.net/lazzo-funda-pene/\n",
      "Pagina 4\n",
      "DIGIT PRO\n",
      "Sensa-Pasión +40º\n",
      "NINA - Vibrador a distancia con braguitas\n",
      "SUNNY BABY - Vibrador masajeador para pecho\n",
      "SWAN - Vibrador con succión sónica\n",
      "TOK anal TURBO\n",
      "ÁTAME FUERTE\n",
      "DANSARA\n",
      "MASAJE-SEXY PRO ¡Relaja Músculos\n",
      "BODICE\n",
      "VIBRA KITTY\n",
      "EUPHORIA\n",
      "MINI CARNIVAL\n",
      "PASSTICIO\n",
      "BOMBONS - delicias anales de silicona\n",
      "TAPATORU\n",
      "Desliz! Eco monodosis\n",
      "VINA - Conjunto de lencería de tiras y rejilla\n",
      "Bacanal FORTE TARRO 200ml\n",
      "PRINCE\n",
      "GOTA-SOFT LARGE\n",
      "ROCKER G\n",
      "GOTICAL\n",
      "HIEDRA\n",
      "https://www.amantis.net/digit-pro-dedal-vibrador-by-amantis/\n",
      "https://www.amantis.net/sensa-pasion-40-doble-vibrador-calor-interno/\n",
      "https://www.amantis.net/nina-vibrador-distancia-braguitas/\n",
      "https://www.amantis.net/sunny-baby-vibrador-masajeador-pecho/\n",
      "https://www.amantis.net/swan-vibrador-succion-sonica/\n",
      "https://www.amantis.net/tok-anal-turbo-el-estimulador-anal-mas-potente/\n",
      "https://www.amantis.net/atame-fuerte-cuerda-bondage-amantis-10-o-20-metros/\n",
      "https://www.amantis.net/dansara-jumpsuit-elegante-potente/\n",
      "https://www.amantis.net/masaje-sexy-pro-relaja-musculos-excita-genitales/\n",
      "https://www.amantis.net/bodice-body-rejilla-pecho-descubierto/\n",
      "https://www.amantis.net/vibra-kitty-vibrador-doble-estimulacion-sin-manos/\n",
      "https://www.amantis.net/euphoria-trasero-dos-orificios-placer/\n",
      "https://www.amantis.net/mini-carnival-mini-masajeador-cuatro-cabezales/\n",
      "https://www.amantis.net/passticio-body-rejilla-abierto-amantis/\n",
      "https://www.amantis.net/bombons-delicias-anales-silicona/\n",
      "https://www.amantis.net/tapatoru-corpino-liguero-medias-efecto-trikini/\n",
      "https://www.amantis.net/desliz-eco-monodosis-pack-10-uds/\n",
      "https://www.amantis.net/vina-conjunto-lenceria-tiras-rejilla/\n",
      "https://www.amantis.net/bacanal-forte-tarro-200ml-lubricante-anal-concentrado-aloe/\n",
      "https://www.amantis.net/prince-vibrador-silicona-rotacion-real/\n",
      "https://www.amantis.net/gota-soft-large-plug-anal-suave-silicona-brillante/\n",
      "https://www.amantis.net/rocker-g-potente-estimulador-punto-g-clitoris/\n",
      "https://www.amantis.net/gotical-choker-sujetador-triangulo/\n",
      "https://www.amantis.net/enredadera-body-sexy-floral/\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.amantis.net/productos-amantis/\"              # lista productos\n",
    "url_principal=\"https://www.amantis.net/\"                        # productos\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "pages= np.arange(1,5)\n",
    "name=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "lista_URLs = []\n",
    "\n",
    "for page in pages:\n",
    "    if page == 1:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url\n",
    "        response = requests.get(url)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        titulos=soup.find_all(\"h3\")\n",
    "\n",
    "        for titulo in titulos:\n",
    "            nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "            name.append(nombre)\n",
    "            description=titulo.get_text(strip=True).split(', ')[1:]\n",
    "            if description==[]:\n",
    "                description=[\"No hay datos\"]\n",
    "            desc.append(description)\n",
    "            print(nombre)\n",
    "\n",
    "        all_price=soup.find_all(\"span\",class_=\"productSpecialPrice\")\n",
    "\n",
    "        for precio in all_price:\n",
    "            item_price=precio.get_text(strip=True).replace(\",\", \".\").split('€')[0]\n",
    "            price.append(item_price)\n",
    "\n",
    "\n",
    "        productos = soup.find_all(class_='caption')\n",
    "\n",
    "        for producto in productos[8:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "            print(URL_producto)\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url+'page' + str(page)+'/'\n",
    "        response = requests.get(URL)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        titulos=soup.find_all(\"h3\")\n",
    "\n",
    "        for titulo in titulos:\n",
    "            nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "            name.append(nombre)\n",
    "            description=titulo.get_text(strip=True).split(', ')[1:]\n",
    "            if description==[]:\n",
    "                description=[\"No hay datos\"]\n",
    "            desc.append(description)\n",
    "            print(nombre)\n",
    "\n",
    "        for precio in all_price:\n",
    "            item_price=precio.get_text(strip=True).replace(\",\", \".\").split('€')[0]\n",
    "            price.append(item_price)\n",
    "\n",
    "        productos = soup.find_all(class_='caption')\n",
    "\n",
    "        for producto in productos[8:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "            print(URL_producto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "print(len(lista_URLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amantis.net/tobogane-hot-rabbit-el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amantis.net/ballenato-tu-vibrador-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amantis.net/meneo-sube-baja-realis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amantis.net/foxtail-plug-anal-cola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amantis.net/lizo-2-dildo-suave-sil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>https://www.amantis.net/prince-vibrador-silico...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>https://www.amantis.net/gota-soft-large-plug-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>https://www.amantis.net/rocker-g-potente-estim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>https://www.amantis.net/gotical-choker-sujetad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>https://www.amantis.net/enredadera-body-sexy-f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 link\n",
       "0   https://www.amantis.net/tobogane-hot-rabbit-el...\n",
       "1   https://www.amantis.net/ballenato-tu-vibrador-...\n",
       "2   https://www.amantis.net/meneo-sube-baja-realis...\n",
       "3   https://www.amantis.net/foxtail-plug-anal-cola...\n",
       "4   https://www.amantis.net/lizo-2-dildo-suave-sil...\n",
       "..                                                ...\n",
       "91  https://www.amantis.net/prince-vibrador-silico...\n",
       "92  https://www.amantis.net/gota-soft-large-plug-a...\n",
       "93  https://www.amantis.net/rocker-g-potente-estim...\n",
       "94  https://www.amantis.net/gotical-choker-sujetad...\n",
       "95  https://www.amantis.net/enredadera-body-sexy-f...\n",
       "\n",
       "[96 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_productos = pd.DataFrame({\"link\":lista_URLs})\n",
    "df_productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOBOGANE HOT RABBIT</td>\n",
       "      <td>[el superventas de amantis ¡mejorado!]</td>\n",
       "      <td>https://www.amantis.net/tobogane-hot-rabbit-el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BALLENATO</td>\n",
       "      <td>[tu vibrador a distancia con aleta móvil y sum...</td>\n",
       "      <td>https://www.amantis.net/ballenato-tu-vibrador-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MENEO sube y baja</td>\n",
       "      <td>[placer realista con control remoto]</td>\n",
       "      <td>https://www.amantis.net/meneo-sube-baja-realis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOXTAIL</td>\n",
       "      <td>[plug anal cola de zorro de 35cm]</td>\n",
       "      <td>https://www.amantis.net/foxtail-plug-anal-cola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIZO 2</td>\n",
       "      <td>[Dildo de suave silicona en 3 tamaños]</td>\n",
       "      <td>https://www.amantis.net/lizo-2-dildo-suave-sil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                        Description  \\\n",
       "0  TOBOGANE HOT RABBIT             [el superventas de amantis ¡mejorado!]   \n",
       "1            BALLENATO  [tu vibrador a distancia con aleta móvil y sum...   \n",
       "2    MENEO sube y baja               [placer realista con control remoto]   \n",
       "3              FOXTAIL                  [plug anal cola de zorro de 35cm]   \n",
       "4               LIZO 2             [Dildo de suave silicona en 3 tamaños]   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.amantis.net/tobogane-hot-rabbit-el...  \n",
       "1  https://www.amantis.net/ballenato-tu-vibrador-...  \n",
       "2  https://www.amantis.net/meneo-sube-baja-realis...  \n",
       "3  https://www.amantis.net/foxtail-plug-anal-cola...  \n",
       "4  https://www.amantis.net/lizo-2-dildo-suave-sil...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_productos = pd.DataFrame({\"Name\": name,\"Description\": desc,\"link\":lista_URLs})\n",
    "df_productos.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifico que he conseguido las URLs de los productos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre producto  TOBOGANE HOT RABBIT\n",
      "Precio  [39.99]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = requests.get(lista_URLs[0])\n",
    "html = response.content\n",
    "soup_producto = bs(html, \"lxml\")\n",
    "# titulo = soup_producto.find('h1').text\n",
    "titulo=soup_producto.get_text(strip=True).split(',')[0]\n",
    "# description=soup_producto.get_text(strip=True).split(',')[1:]                   #  Tengo que ver como extraer unicamente la información\n",
    "# if description==[]:\n",
    "#     description=[\"No hay datos\"]\n",
    "\n",
    "all_price = soup_producto.find_all(\"span\",class_=\"productSpecialPrice\")\n",
    "price = [float(x.get_text(strip=True).replace(\",\", \".\").split('€')[0]) for x in all_price]\n",
    "\n",
    "print(\"Nombre producto \",titulo)\n",
    "# print(\"Descripción \",description)\n",
    "\n",
    "print(\"Precio \",price)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer la información de producto, descripción, enlace y precio tomando los datos desde las URLs de cada producto.\n",
    "\n",
    "Queda pendiente extraer información de los ratings y los comentarios para establecer un estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina 1\n",
      "Pagina 2\n",
      "Pagina 3\n",
      "Pagina 4\n",
      "Pagina 5\n",
      "Pagina 6\n",
      "Pagina 7\n",
      "Pagina 8\n",
      "Pagina 9\n",
      "Pagina 10\n",
      "Pagina 11\n",
      "Pagina 12\n",
      "Pagina 13\n",
      "Pagina 14\n",
      "Pagina 15\n",
      "Pagina 16\n",
      "Pagina 17\n",
      "Pagina 18\n",
      "Pagina 19\n",
      "Pagina 20\n",
      "Pagina 21\n",
      "Pagina 22\n",
      "Pagina 23\n",
      "Pagina 24\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.amantis.net/productos-amantis/\"              # lista productos\n",
    "url_principal=\"https://www.amantis.net/\"                        # productos\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "pages= np.arange(1, 25)\n",
    "name=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "lista_URLs = []\n",
    "\n",
    "for page in pages:\n",
    "    if page == 1:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url\n",
    "        response = requests.get(url)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        titulos=soup.find_all(\"h3\")\n",
    "\n",
    "        for titulo in titulos[1:]:\n",
    "            nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "            name.append(nombre)\n",
    "            description=titulo.get_text(strip=True).split(', ')[1:]\n",
    "            if description==[]:\n",
    "                description=[\"No hay datos\"]\n",
    "            desc.append(description)\n",
    "\n",
    "        all_price=soup.find_all(\"span\",class_=\"productSpecialPrice\")\n",
    "\n",
    "        for precio in all_price:\n",
    "            item_price=precio.get_text(strip=True).replace(\",\", \".\").split('€')[0]\n",
    "            price.append(item_price)\n",
    "\n",
    "\n",
    "        productos = soup.find_all(class_='caption')\n",
    "\n",
    "        for producto in productos[8:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url+'page' + str(page)+'/'\n",
    "        response = requests.get(URL)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        titulos=soup.find_all(\"h3\")\n",
    "\n",
    "        for titulo in titulos:\n",
    "            nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "            name.append(nombre)\n",
    "            description=titulo.get_text(strip=True).split(', ')[1:]\n",
    "            if description==[]:\n",
    "                description=[\"No hay datos\"]\n",
    "            desc.append(description)\n",
    "\n",
    "        for precio in all_price:\n",
    "            item_price=precio.get_text(strip=True).replace(\",\", \".\").split('€')[0]\n",
    "            price.append(item_price)\n",
    "\n",
    "        productos = soup.find_all(class_='caption')\n",
    "\n",
    "        for producto in productos[8:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_productos = pd.DataFrame({\"Name\": name,\"Description\": desc,\"Price\":price,\"link\":lista_URLs})\n",
    "# df_productos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres: 576\n",
      "descrip: 576\n",
      "precio: 552\n",
      "URL: 576\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombres:\" ,len(name))\n",
    "print(\"descrip:\" ,len(desc))\n",
    "print(\"precio:\" ,len(price))                    #  Se ve que hay un desajuste en el precio al extraer la información de 1 pagina\n",
    "print(\"URL:\" ,len(lista_URLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres:\n",
      " ['TOBOGANE HOT RABBIT', 'BALLENATO', 'MENEO sube y baja', 'FOXTAIL', 'LIZO 2']\n",
      "descrip:\n",
      " [['el superventas de amantis ¡mejorado!'], ['tu vibrador a distancia con aleta móvil y sumergible...'], ['placer realista con control remoto'], ['plug anal cola de zorro de 35cm'], ['Dildo de suave silicona en 3 tamaños']]\n",
      "precio:\n",
      " ['39.99', '43.99', '44.99', '9.99', '17.99']\n",
      "URL:\n",
      " ['https://www.amantis.net/tobogane-hot-rabbit-el-superventas-amantis-mejorado/', 'https://www.amantis.net/ballenato-tu-vibrador-distancia-aleta-movil-sumergible/', 'https://www.amantis.net/meneo-sube-baja-realista-control-remoto/', 'https://www.amantis.net/foxtail-plug-anal-cola-zorro/', 'https://www.amantis.net/lizo-2-dildo-suave-silicona-3-tamanos/']\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombres:\\n\" ,name[:5])\n",
    "print(\"descrip:\\n\" ,desc[:5])\n",
    "print(\"precio:\\n\" ,price[:5])\n",
    "print(\"URL:\\n\" ,lista_URLs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentando extraer la información de ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BALLENATO\n"
     ]
    }
   ],
   "source": [
    "prueba=lista_URLs[1]\n",
    "response = requests.get(prueba)\n",
    "soup_prueba = bs(response.text, 'lxml')\n",
    "\n",
    "titulo=soup_prueba.get_text(strip=True).split(',')[0]\n",
    "print(titulo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto consigo extraer la información de las fechas de los comentarios,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [254], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m rating_coment_3\u001b[39m=\u001b[39mrating_coment_2\u001b[39m.\u001b[39msplit(sep_1)[\u001b[39m1\u001b[39m:]\n\u001b[0;32m     10\u001b[0m date_1\u001b[39m=\u001b[39mrating_coment_3[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrating_coment_3[\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m date_2\u001b[39m=\u001b[39mdatetime(date_1\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrating_coment_1)\n\u001b[0;32m     12\u001b[0m \u001b[39m# date_object = datetime.strptime(date_2,'%d%m%Y')\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[39m# print(type(date_1))\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# print(date_1)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# rating.append(date_object)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(date_2))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "rating=[]\n",
    "all_ratings = soup_prueba.find_all(\"span\", class_=\"date\")  \n",
    "sep_1=(' ')\n",
    "sep_2=(', ')\n",
    "# pattern = re.compile(sep)\n",
    "for ratings in all_ratings:\n",
    "    rating_coment_1=ratings.get_text(strip=True).split(sep_2)[1]\n",
    "    rating_coment_2=ratings.get_text(strip=True).split(sep_2)[0]\n",
    "    rating_coment_3=rating_coment_2.split(sep_1)[1:]\n",
    "    date_1=rating_coment_3[0]+\"/\"+rating_coment_3[1]\n",
    "    date_2=date_1+\"/\"+rating_coment_1                                       # Estamos pendientes de convertir a fechas, teniendo en cuenta\n",
    "    date_object = datetime.strptime(date_2,'%d%m%Y')                        # que esta en español\n",
    "    \n",
    "    # print(type(date_1))\n",
    "    # print(date_1)\n",
    "    # rating.append(date_object)\n",
    "    print(type(date_2))\n",
    "    print(date_2)\n",
    "\n",
    "# print(len(rating))\n",
    "rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto consigo extraer la información de los usuarios que han comentado, en el caso que no haya datos ver como modificarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tomabel'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_comments=[]\n",
    "all_user_comments = soup_prueba.find_all(\"span\", class_=\"name-user\")  \n",
    "\n",
    "for user_comment in all_user_comments:\n",
    "    user_comments.append(user_comment.get_text(strip=True))\n",
    "\n",
    "print(len(user_comments))\n",
    "user_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_comments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí extraigo la información de los comentarios y los meto en una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me lo regaló mi pareja y la verdad es que nos encanto! lo estamos incorporando más a nuestro día a día y nos parece de lo más!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment=[]\n",
    "all_comments = soup_prueba.find_all(\"p\")\n",
    "for formats in all_comments[-len(rating):]:\n",
    "    comment.append(formats.get_text(strip=True))\n",
    "\n",
    "print(comment[1])\n",
    "len(comment)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo puedo saber la valoración que tienen los productos? \n",
    "\n",
    "data_prefix=far es que no tiene punto\n",
    "data_prefix=fas es que tiene un punto hasta un máximo de 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"box-description\">\n",
       " <span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"far fa-heart\"></span> <span class=\"date\">lunes 05 diciembre, 2022</span>\n",
       " </div>,\n",
       " <div class=\"box-description\">\n",
       " <span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span> <span class=\"date\">miércoles 16 noviembre, 2022</span>\n",
       " </div>,\n",
       " <div class=\"box-description\">\n",
       " <span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span><span class=\"fas fa-heart\"></span> <span class=\"date\">lunes 30 mayo, 2022</span>\n",
       " </div>]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hearts = soup_prueba.find_all(\"div\",class_=\"box-description\")\n",
    "\n",
    "# hearts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hearts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [63], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# hearts = soup_prueba.find_all(\"span\",class_=\"svg-inline--fa fa-heart fa-w-18\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# hearts = soup_prueba.get_text(\"svg\")\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m hearts\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hearts' is not defined"
     ]
    }
   ],
   "source": [
    "# hearts = soup_prueba.find_all(\"span\",class_=\"svg-inline--fa fa-heart fa-w-18\")\n",
    "# hearts = soup_prueba.get_text(\"svg\")\n",
    "hearts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a extraer la información de la descripción de cada producto, lo anterior era el subtitulo,\n",
    "\n",
    "hay que buscar otro método para extraer esta información para poder guardarla correctamente.\n",
    "\n",
    "Los rangos no cuadran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# prueba_2=rating.get_text()\n",
    "# prueba_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar a agregar datos dentro del bucle inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina 1\n",
      "Pagina 2\n",
      "Pagina 3\n",
      "Pagina 4\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.amantis.net/productos-amantis/\"              # lista productos\n",
    "url_principal=\"https://www.amantis.net/\"                        # productos\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "pages= np.arange(1,5)\n",
    "# pages= np.arange(1, 25)\n",
    "name=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "lista_URLs = []\n",
    "user_comments=[]\n",
    "comment=[]\n",
    "rating=[]\n",
    "\n",
    "\n",
    "for page in pages:\n",
    "    if page == 1:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url\n",
    "        response = requests.get(url)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "\n",
    "        titulos=soup.find_all(\"h3\")\n",
    "        for titulo in titulos[1:]:\n",
    "            nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "            name.append(nombre)\n",
    "            description=titulo.get_text(strip=True).split(', ')[1:]\n",
    "            if description==[]:\n",
    "                description=[\"No hay datos\"]\n",
    "            desc.append(description)\n",
    "\n",
    "        all_price=soup.find_all(\"span\",class_=\"productSpecialPrice\")\n",
    "        for precio in all_price:\n",
    "            item_price=precio.get_text(strip=True).replace(\",\", \".\").split('€')[0]\n",
    "            price.append(item_price)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url+'page' + str(page)+'/'\n",
    "        response = requests.get(URL)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        titulos=soup.find_all(\"h3\")\n",
    "\n",
    "        for titulo in titulos:\n",
    "            nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "            name.append(nombre)\n",
    "            description=titulo.get_text(strip=True).split(', ')[1:]\n",
    "            if description==[]:\n",
    "                description=[\"No hay datos\"]\n",
    "            desc.append(description)\n",
    "\n",
    "        all_price=soup.find_all(\"span\",class_=\"productSpecialPrice\")\n",
    "        for precio in all_price:\n",
    "            item_price=precio.get_text(strip=True).replace(\",\", \".\").split('€')[0]\n",
    "            price.append(item_price)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombres:\" ,len(name))\n",
    "print(\"descrip:\" ,len(desc))\n",
    "print(\"precio:\" ,len(price))                    #  Se ve que hay un desajuste en el precio al extraer la información de 1 pagina\n",
    "print(\"URL:\" ,len(lista_URLs))\n",
    "print(\"dates:\" ,len(rating))\n",
    "print(\"Comentarios:\" ,len(comment))\n",
    "print(\"Usuarios:\" ,len(user_comments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombres:\\n\" ,name[:5])\n",
    "print(\"descrip:\\n\" ,desc[:5])\n",
    "print(\"precio:\\n\" ,price[:5])\n",
    "print(\"URL:\\n\" ,lista_URLs[:5])\n",
    "print(\"dates:\\n\" ,rating[:5])\n",
    "print(\"Comentarios:\\n\" ,comment[:5])          # Esto no lo coge bien\n",
    "print(\"Usuarios:\\n\" ,user_comments[:5])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este trozo de codigo obtengo la información relevante del producto y la separo en descripción y características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "[['martes 22 noviembre, 2022'], ['jueves 07 julio, 2022'], ['sábado 23 abril, 2022'], ['jueves 07 abril, 2022'], ['sábado 26 marzo, 2022'], ['lunes 31 enero, 2022'], ['domingo 26 diciembre, 2021'], ['lunes 20 diciembre, 2021'], ['martes 23 noviembre, 2021'], ['viernes 08 octubre, 2021'], ['lunes 13 septiembre, 2021'], ['miércoles 01 septiembre, 2021'], ['miércoles 11 agosto, 2021'], ['lunes 07 junio, 2021'], ['lunes 05 abril, 2021'], ['viernes 05 marzo, 2021'], ['jueves 26 noviembre, 2020'], ['martes 24 noviembre, 2020'], ['jueves 12 noviembre, 2020'], ['viernes 18 septiembre, 2020']]\n",
      "--------------------\n",
      "longitud: 20\n",
      "--------------------\n",
      "--------------------\n",
      "[['miércoles 01 febrero, 2023'], ['viernes 18 noviembre, 2022'], ['martes 06 septiembre, 2022'], ['miércoles 13 julio, 2022'], ['viernes 17 junio, 2022'], ['viernes 05 noviembre, 2021'], ['martes 06 julio, 2021'], ['lunes 24 mayo, 2021'], ['domingo 16 mayo, 2021'], ['viernes 30 abril, 2021'], ['viernes 16 abril, 2021'], ['lunes 01 marzo, 2021'], ['martes 09 febrero, 2021'], ['miércoles 13 enero, 2021'], ['jueves 26 noviembre, 2020'], ['miércoles 04 noviembre, 2020'], ['viernes 25 septiembre, 2020'], ['lunes 21 septiembre, 2020'], ['lunes 14 septiembre, 2020']]\n",
      "--------------------\n",
      "longitud: 19\n",
      "--------------------\n",
      "[[['martes 22 noviembre, 2022'], ['jueves 07 julio, 2022'], ['sábado 23 abril, 2022'], ['jueves 07 abril, 2022'], ['sábado 26 marzo, 2022'], ['lunes 31 enero, 2022'], ['domingo 26 diciembre, 2021'], ['lunes 20 diciembre, 2021'], ['martes 23 noviembre, 2021'], ['viernes 08 octubre, 2021'], ['lunes 13 septiembre, 2021'], ['miércoles 01 septiembre, 2021'], ['miércoles 11 agosto, 2021'], ['lunes 07 junio, 2021'], ['lunes 05 abril, 2021'], ['viernes 05 marzo, 2021'], ['jueves 26 noviembre, 2020'], ['martes 24 noviembre, 2020'], ['jueves 12 noviembre, 2020'], ['viernes 18 septiembre, 2020']], [['miércoles 01 febrero, 2023'], ['viernes 18 noviembre, 2022'], ['martes 06 septiembre, 2022'], ['miércoles 13 julio, 2022'], ['viernes 17 junio, 2022'], ['viernes 05 noviembre, 2021'], ['martes 06 julio, 2021'], ['lunes 24 mayo, 2021'], ['domingo 16 mayo, 2021'], ['viernes 30 abril, 2021'], ['viernes 16 abril, 2021'], ['lunes 01 marzo, 2021'], ['martes 09 febrero, 2021'], ['miércoles 13 enero, 2021'], ['jueves 26 noviembre, 2020'], ['miércoles 04 noviembre, 2020'], ['viernes 25 septiembre, 2020'], ['lunes 21 septiembre, 2020'], ['lunes 14 septiembre, 2020']]]\n",
      "--------------------\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "URL=lista_URLs[:2]\n",
    "\n",
    "\n",
    "# name=[]\n",
    "# desc=[]\n",
    "# price=[]\n",
    "# lista_URLs = []\n",
    "user_comments=[]\n",
    "comment=[]\n",
    "date=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in URL:\n",
    "    prueba=i\n",
    "    response = requests.get(prueba)\n",
    "    soup_prueba = bs(response.text, 'lxml')\n",
    "    user_comments_product=[]\n",
    "    date_comments_product=[]\n",
    "    comments_product=[]\n",
    "\n",
    "    # information=soup_prueba.find(\"div\", class_=\"description\") \n",
    "    # info=information.get_text().split('\\n')[1:5]\n",
    "    # name.append(info)\n",
    "    # caract=information.get_text().split('\\n')[5:-3]\n",
    "    # desc.append(caract)\n",
    "\n",
    "    # all_user_comments = soup_prueba.find_all(\"span\", class_=\"name-user\") \n",
    "    # for user_comment in all_user_comments:\n",
    "    #     user_comments_product.append(user_comment.get_text(strip=True))\n",
    "    # user_comments.append(user_comments_product)\n",
    "\n",
    "    all_dates = soup_prueba.find_all(\"span\", class_=\"date\")  \n",
    "    for dates in all_dates:\n",
    "        date_comments_product.append(dates.get_text(strip=True).split(\" \\d\"))\n",
    "    date.append(date_comments_product)\n",
    "\n",
    "    # all_comments = soup_prueba.find_all(\"p\")\n",
    "    # for formats in all_comments[-len(date_comments_product):]:\n",
    "    #     comments_product.append(formats.get_text(strip=True))\n",
    "    # comment.append(comments_product)\n",
    "\n",
    "\n",
    "    # print(info)\n",
    "    # print('-'*20)\n",
    "    # print(caract)\n",
    "    # print('-'*20)\n",
    "    # print(user_comments_product)\n",
    "    print('-'*20)\n",
    "    print(date_comments_product)\n",
    "    print('-'*20)\n",
    "    print(\"longitud:\",len(date_comments_product))\n",
    "    print('-'*20)\n",
    "    # print(comments_product)\n",
    "    # print('-'*20)\n",
    "    # print(\"longitud:\",len(comments_product))\n",
    "    # print('-'*20)\n",
    "# print('-'*20)\n",
    "# print(name)\n",
    "# print('-'*20)\n",
    "# print(len(name))\n",
    "# print('-'*20)\n",
    "# print(desc)\n",
    "# print('-'*20)\n",
    "# print(user_comments)\n",
    "# print('-'*20)\n",
    "# print(len(user_comments))\n",
    "# print('-'*20)\n",
    "# print(comment)\n",
    "# print('-'*20)\n",
    "# print(len(comment))\n",
    "# print('-'*20)\n",
    "print(date)\n",
    "print('-'*20)\n",
    "print(len(date))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.amantis.net/tobogane-hot-rabbit-el-superventas-amantis-mejorado/', 'https://www.amantis.net/ballenato-tu-vibrador-distancia-aleta-movil-sumergible/']\n"
     ]
    }
   ],
   "source": [
    "URL=lista_URLs[:2]\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Este es el código bueno para obtener la información de las páginas.\n",
    "\n",
    "Queda pendiente de agregar nuevos parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pagina 1\n",
      "Pagina 2\n",
      "Pagina 3\n",
      "Pagina 4\n",
      "Pagina 5\n",
      "Pagina 6\n",
      "Pagina 7\n",
      "Pagina 8\n",
      "Pagina 9\n",
      "Pagina 10\n",
      "Pagina 11\n",
      "Pagina 12\n",
      "Pagina 13\n",
      "Pagina 14\n",
      "Pagina 15\n",
      "Pagina 16\n",
      "Pagina 17\n",
      "Pagina 18\n",
      "Pagina 19\n",
      "Pagina 20\n",
      "Pagina 21\n",
      "Pagina 22\n",
      "Pagina 23\n",
      "Pagina 24\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n",
      "--------------------\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.amantis.net/productos-amantis/\"              # lista productos\n",
    "url_principal=\"https://www.amantis.net/\"                        # productos\n",
    "# pages= np.arange(1,5)\n",
    "pages= np.arange(1, 25)\n",
    "\n",
    "'''Listas a generar con la información de los productos'''\n",
    "lista_URLs = []\n",
    "name=[]\n",
    "subname=[]\n",
    "regular_prices=[]\n",
    "new_price=[]\n",
    "# lista_URLs = []\n",
    "info=[]\n",
    "charac=[]\n",
    "user_comments=[]\n",
    "comment=[]\n",
    "date=[]\n",
    "\n",
    "''' Obtenemos las URLs de los productos para entrar luego en sus URLS y extraer la información'''\n",
    "\n",
    "for page in pages:\n",
    "    if page == 1:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url\n",
    "        response = requests.get(url)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        productos = soup.find_all(class_='caption')\n",
    "        for producto in productos[8:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "        \n",
    "    else:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url+'page' + str(page)+'/'\n",
    "        response = requests.get(URL)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        productos = soup.find_all(class_='caption')\n",
    "        for producto in productos[8:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "\n",
    "'''Extraemos la información de cada producto existente'''\n",
    "\n",
    "for URL in lista_URLs:\n",
    "    url_product=URL\n",
    "    response_product = requests.get(url_product)\n",
    "    soup_product = bs(response_product.text, 'lxml')\n",
    "    user_comments_product=[]\n",
    "    date_comments_product=[]\n",
    "    comments_product=[]\n",
    "\n",
    "    titulos=soup_product.find_all(\"h1\",class_=\"h3\")\n",
    "    for titulo in titulos:\n",
    "        nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "        name.append(nombre)\n",
    "        sub_title=titulo.get_text(strip=True).split(', ')[1:]\n",
    "        if sub_title==[]:\n",
    "            sub_title=[\"No hay datos\"]\n",
    "        subname.append(sub_title)\n",
    "\n",
    "    all_price = soup_product.find_all(\"div\", class_=\"productoPrecio pull-right tdd_precio\")                        \n",
    "    for price_container in all_price:                                                                    \n",
    "        try:\n",
    "            special_price = price_container.find(\"span\", class_=\"productSpecialPrice\")\n",
    "            if special_price:\n",
    "                item_price = float(special_price.get_text(strip=True).replace(\",\", \".\").split('€')[0])\n",
    "                new_price.append(item_price)\n",
    "                regular_price = price_container.find(\"del\").get_text(strip=True)\n",
    "                item_regular_price = float(regular_price.replace(\",\", \".\").split('€')[0])\n",
    "                regular_prices.append(item_regular_price)\n",
    "            else:\n",
    "                regular_price = price_container.find(\"span\").get_text(strip=True)\n",
    "                item_regular_price = float(regular_price.replace(\",\", \".\").split('€')[0])\n",
    "                new_price.append(item_regular_price)\n",
    "                regular_prices.append(None)\n",
    "        except:\n",
    "            new_price.append(None)\n",
    "            regular_prices.append(None)\n",
    "\n",
    "    description=soup_product.find(\"div\", class_=\"description\") \n",
    "    information=description.get_text().split('\\n')[1:5]\n",
    "    info.append(information)\n",
    "    characteristic=description.get_text().split('\\n')[5:-3]\n",
    "    charac.append(characteristic)\n",
    "\n",
    "    all_user_comments = soup_product.find_all(\"span\", class_=\"name-user\") \n",
    "    for user_comment in all_user_comments:\n",
    "        user_comments_product.append(user_comment.get_text(strip=True))\n",
    "    user_comments.append(user_comments_product)\n",
    "\n",
    "    all_dates = soup_product.find_all(\"span\", class_=\"date\")  \n",
    "    for dates in all_dates:\n",
    "        dates_text=dates.get_text(strip=True)\n",
    "        # dates=datetime.strftime(dates, '%dd/%mm/%Y')\n",
    "        date_comments_product.append(dates_text)\n",
    "        # date_object = datetime.strptime(date_comments_product)\n",
    "    date.append(date_comments_product)\n",
    "\n",
    "    all_comments = soup_product.find_all(\"p\")\n",
    "    for formats in all_comments[-len(date_comments_product):]:\n",
    "        comments_product.append(formats.get_text(strip=True))\n",
    "    comment.append(comments_product)\n",
    "\n",
    "for i, regular_price in enumerate(regular_prices):\n",
    "    if regular_price is None:\n",
    "        regular_prices[i] = new_price[i]\n",
    "\n",
    "\n",
    "# print('-'*20)\n",
    "# print(name)\n",
    "print('-'*20)\n",
    "print(len(name))\n",
    "# print('-'*20)\n",
    "# print(subname)\n",
    "print('-'*20)\n",
    "print(len(subname))\n",
    "print('-'*20)\n",
    "# print(regular_prices)\n",
    "# print('-'*20)\n",
    "print(len(regular_prices))\n",
    "\n",
    "# print('-'*20)\n",
    "# print(new_price)\n",
    "print('-'*20)\n",
    "print(len(new_price))\n",
    "print('-'*20)\n",
    "print(len(lista_URLs))\n",
    "# print('-'*20)\n",
    "# print(lista_URLs)\n",
    "\n",
    "\n",
    "# # print('-'*20)\n",
    "# # print(info)\n",
    "print('-'*20)\n",
    "print(len(info))\n",
    "# print('-'*20)\n",
    "# # print(charac)\n",
    "print('-'*20)\n",
    "print(len(charac))\n",
    "# print('-'*20)\n",
    "# # print(user_comments)\n",
    "print('-'*20)\n",
    "print(len(user_comments))\n",
    "# print('-'*20)\n",
    "# # print(comment)\n",
    "print('-'*20)\n",
    "print(len(comment))\n",
    "# # print('-'*20)\n",
    "# # print(date)\n",
    "print('-'*20)\n",
    "print(len(date))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui vamos a seguir haciendo pruebas para extraer la información de los datos de *corazones* de *comments*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amantis.net/productos-amantis/\"              # lista productos\n",
    "url_principal=\"https://www.amantis.net/\"                        # productos\n",
    "# pages= np.arange(1,5)\n",
    "pages= np.arange(1, 25)\n",
    "\n",
    "'''Listas a generar con la información de los productos'''\n",
    "lista_URLs = []\n",
    "name=[]\n",
    "# subname=[]\n",
    "# regular_prices=[]\n",
    "# new_price=[]\n",
    "# # lista_URLs = []\n",
    "# info=[]\n",
    "# charac=[]\n",
    "user_comments=[]\n",
    "comment=[]\n",
    "date=[]\n",
    "\n",
    "''' Obtenemos las URLs de los productos para entrar luego en sus URLS y extraer la información'''\n",
    "\n",
    "for page in pages:\n",
    "    if page == 1:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url\n",
    "        response = requests.get(url)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        productos = soup.find_all(class_='caption')\n",
    "        for producto in productos[8:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "        \n",
    "    else:\n",
    "        print(\"Pagina\",page)\n",
    "        URL = url+'page' + str(page)+'/'\n",
    "        response = requests.get(URL)\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        productos = soup.find_all(class_='caption')\n",
    "        for producto in productos[8:]:\n",
    "            URL_producto = producto.find('a')['href']\n",
    "            lista_URLs.append(URL_producto)\n",
    "\n",
    "'''Extraemos la información de cada producto existente'''\n",
    "\n",
    "for URL in lista_URLs:\n",
    "    url_product=URL\n",
    "    response_product = requests.get(url_product)\n",
    "    soup_product = bs(response_product.text, 'lxml')\n",
    "    user_comments_product=[]\n",
    "    date_comments_product=[]\n",
    "    comments_product=[]\n",
    "\n",
    "    titulos=soup_product.find_all(\"h1\",class_=\"h3\")\n",
    "    for titulo in titulos:\n",
    "        nombre=titulo.get_text(strip=True).split(',')[0]\n",
    "        name.append(nombre)\n",
    "        sub_title=titulo.get_text(strip=True).split(', ')[1:]\n",
    "        if sub_title==[]:\n",
    "            sub_title=[\"No hay datos\"]\n",
    "        subname.append(sub_title)\n",
    "\n",
    "    all_user_comments = soup_product.find_all(\"span\", class_=\"name-user\") \n",
    "    for user_comment in all_user_comments:\n",
    "        user_comments_product.append(user_comment.get_text(strip=True))\n",
    "    user_comments.append(user_comments_product)\n",
    "\n",
    "    all_dates = soup_product.find_all(\"span\", class_=\"date\")  \n",
    "    for dates in all_dates:\n",
    "        dates_text=dates.get_text(strip=True)\n",
    "        # dates=datetime.strftime(dates, '%dd/%mm/%Y')\n",
    "        date_comments_product.append(dates_text)\n",
    "        # date_object = datetime.strptime(date_comments_product)\n",
    "    date.append(date_comments_product)\n",
    "\n",
    "    all_comments = soup_product.find_all(\"p\")\n",
    "    for formats in all_comments[-len(date_comments_product):]:\n",
    "        comments_product.append(formats.get_text(strip=True))\n",
    "    comment.append(comments_product)\n",
    "\n",
    "'''Este codigo de aquí no es necesario para el punto corazones'''\n",
    "\n",
    "    # all_price = soup_product.find_all(\"div\", class_=\"productoPrecio pull-right tdd_precio\")                        \n",
    "    # for price_container in all_price:                                                                    \n",
    "    #     try:\n",
    "    #         special_price = price_container.find(\"span\", class_=\"productSpecialPrice\")\n",
    "    #         if special_price:\n",
    "    #             item_price = float(special_price.get_text(strip=True).replace(\",\", \".\").split('€')[0])\n",
    "    #             new_price.append(item_price)\n",
    "    #             regular_price = price_container.find(\"del\").get_text(strip=True)\n",
    "    #             item_regular_price = float(regular_price.replace(\",\", \".\").split('€')[0])\n",
    "    #             regular_prices.append(item_regular_price)\n",
    "    #         else:\n",
    "    #             regular_price = price_container.find(\"span\").get_text(strip=True)\n",
    "    #             item_regular_price = float(regular_price.replace(\",\", \".\").split('€')[0])\n",
    "    #             new_price.append(item_regular_price)\n",
    "    #             regular_prices.append(None)\n",
    "    #     except:\n",
    "    #         new_price.append(None)\n",
    "    #         regular_prices.append(None)\n",
    "\n",
    "    # description=soup_product.find(\"div\", class_=\"description\") \n",
    "    # information=description.get_text().split('\\n')[1:5]\n",
    "    # info.append(information)\n",
    "    # characteristic=description.get_text().split('\\n')[5:-3]\n",
    "    # charac.append(characteristic)\n",
    "\n",
    "\n",
    "# for i, regular_price in enumerate(regular_prices):\n",
    "#     if regular_price is None:\n",
    "#         regular_prices[i] = new_price[i]\n",
    "\n",
    "\n",
    "# print('-'*20)\n",
    "# print(name)\n",
    "print('-'*20)\n",
    "print(len(name))\n",
    "# print('-'*20)\n",
    "# print(subname)\n",
    "print('-'*20)\n",
    "print(len(subname))\n",
    "print('-'*20)\n",
    "# # print(regular_prices)\n",
    "# # print('-'*20)\n",
    "# print(len(regular_prices))\n",
    "\n",
    "# # print('-'*20)\n",
    "# # print(new_price)\n",
    "# print('-'*20)\n",
    "# print(len(new_price))\n",
    "# print('-'*20)\n",
    "# print(len(lista_URLs))\n",
    "# # print('-'*20)\n",
    "# print(lista_URLs)\n",
    "\n",
    "\n",
    "# # print('-'*20)\n",
    "# # print(info)\n",
    "# print('-'*20)\n",
    "# print(len(info))\n",
    "# # print('-'*20)\n",
    "# # # print(charac)\n",
    "# print('-'*20)\n",
    "# print(len(charac))\n",
    "# # print('-'*20)\n",
    "# # print(user_comments)\n",
    "print('-'*20)\n",
    "print(len(user_comments))\n",
    "# print('-'*20)\n",
    "# # print(comment)\n",
    "print('-'*20)\n",
    "print(len(comment))\n",
    "# # print('-'*20)\n",
    "# # print(date)\n",
    "print('-'*20)\n",
    "print(len(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating_producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = np.arange(1, 3)\n",
    "# count = 1\n",
    "# lista_libros = []\n",
    "\n",
    "# for page in pages:\n",
    "    \n",
    "#     URL = url+'/page/' + str(page)\n",
    "#     r = requests.get(URL)\n",
    "#     soup = bs(r.text, 'lxml')\n",
    "#     libros_grid = soup.find_all(class_='item-img')\n",
    "    \n",
    "#     count_libro = 1 # para el print de seguimiento de descarga\n",
    "    \n",
    "#     for libro in libros_grid:\n",
    "#         # Print de seguimiento de descarga:\n",
    "#         print('Libro {} de {}, pag {}/{}'.format(\n",
    "#             count_libro, len(libros_grid), page, len(pages)))\n",
    "\n",
    "#         URL_libro = libro.find('a')['href']\n",
    "#         r = requests.get(url_principal + URL_libro)\n",
    "#         soup_libro = bs(r.text, 'lxml')\n",
    "        \n",
    "        # id_libro = 'lb_' + str(count)\n",
    "        \n",
    "        # name = soup_libro.find('h1').text   \n",
    "        # try:\n",
    "        #     price = float(soup_libro.find(class_ = 'sale-price').text.split(' ')[0].replace(',','.'))\n",
    "\n",
    "        # except:\n",
    "        #     price = None\n",
    "\n",
    "        # try :\n",
    "        #     author = soup_libro.find(class_ = 'item-annotation-wrap')('h2')[2].text[6:]\n",
    "\n",
    "        # except:\n",
    "        #     author = soup_libro.find(class_ = 'item-info')('span')[-1].text.split('\\n                                    ')[-1]\n",
    "\n",
    "        # formats = soup_libro.find(class_ = 'meta-info hidden-md')('li')[0].text\n",
    "\n",
    "        # try:\n",
    "        #     rating = soup_libro.find(class_ = 'rating-wrap hidden-md')('span')[5].text.split(' ')[-1].replace(',','.')\n",
    "        #     rating = float(rating)\n",
    "        \n",
    "        # except:\n",
    "        #     rating = None\n",
    "        \n",
    "        # try:    \n",
    "        #     rating_count = soup_libro.find(class_ = 'rating-wrap hidden-md')('span')[-1].text.split(' ')[-6].replace('(','').replace('.','')\n",
    "        #     rating_count = int(rating_count)\n",
    "        \n",
    "        # except:\n",
    "        #     rating_count = None\n",
    "\n",
    "        # imagen = soup_libro.find(class_ = 'book-img')['src']\n",
    "\n",
    "        # data = {\"name\": name}\n",
    "\n",
    "\n",
    "        # data = {\"id_libro\": id_libro,\n",
    "        #         \"name\": name,\n",
    "        #         \"price\": price,\n",
    "        #         \"author\": author,\n",
    "        #         \"format\": formats,\n",
    "        #         \"rating\": rating,\n",
    "        #         \"rating_count\": rating_count,\n",
    "        #         \"imagen\": imagen}\n",
    "\n",
    "        # lista_libros.append(data)\n",
    "        \n",
    "        # # Pasamos al siguiente id\n",
    "        # count += 1\n",
    "        # count_libro += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista_libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup.find_all(“h3”) encuentra cada elemento h3 en la página web; con class_=”title” especificamos que buscamos específicamente etiquetas h3 que contengan el atributo class_=”title” (nota importante: el “_” en **class__=”title”** no es un error tipográfico, se requiere en Beautiful Soup cuando seleccionando atributos de clase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los elementos h3 en all_h3, que se comporta como una lista, por lo que podemos recorrerlos con un bucle for. En cada iteración extraemos solo el texto del elemento h3 con .get_text(), y con el parámetro strip=True nos aseguramos de eliminar cualquier espacio en blanco innecesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener los formatos de los libros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del paso anterior tenemos todos los títulos de libros de la página de los más vendidos. Pero, ¿qué sabemos acerca de sus formatos? ¿Hay más libros de tapa dura o tapa blanda?\n",
    "\n",
    "Averigüémoslo inspeccionando el elemento de formato de libro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como siempre inspeccionamos y buscamos el formato.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y como queremos saber la cantidad de cada formato lo metemos en dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_formats = soup.find_all(\"p\", class_=\"format\")\n",
    "# for format in all_formats:\n",
    "#        print(format.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formats = soup.select(\"div.item-info p.format\") # div y p son etiquetas donde se encuentran\n",
    "# formats_series = pd.Series(formats)\n",
    "# formats_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener las fechas de publicación (find_all + get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que antes inspeccionamos...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = soup.find_all(\"p\", class_=\"published\")\n",
    "# dates = [date.get_text()for date in dates] #con esta list comprehension obtenemos solo el año\n",
    "# dates_series = pd.Series(dates)\n",
    "# dates_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = soup.find_all(\"p\", class_=\"published\")\n",
    "# dates = [date.get_text()[-4:] for date in dates] #con esta list comprehension obtenemos solo el año\n",
    "# dates_series = pd.Series(dates)\n",
    "# dates_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener los precios (find_all + get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionamos.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prices = soup.find_all(\"p\", class_=\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"price\">\n",
      "<span class=\"sale-price\">17,53 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">19,26 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">22,00 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">12,89 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">14,46 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">14,15 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">14,50 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">12,95 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">12,79 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">13,50 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">12,37 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">12,50 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">17,34 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">14,15 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">14,50 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">15,25 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">14,98 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">13,21 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">17,34 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">23,51 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">13,23 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">21,67 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">22,00 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">20,91 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">22,00 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">15,64 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">63,83 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">13,44 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">14,88 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">17,00 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">13,67 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">12,99 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">12,81 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">14,21 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">25,04 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">26,50 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">14,59 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">50,68 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">54,00 €</span>\n",
      "</p>, <p class=\"price\">\n",
      "<span class=\"sale-price\">22,53 €</span>\n",
      "<span class=\"rrp-label\">\n",
      "<a href=\"/es/help/topic/HelpId/RRP#helpContent\">\n",
      "                                        PVPR</a>:\n",
      "                                </span>\n",
      "                            \n",
      "                             <span class=\"rrp omnibus\">23,77 €</span>\n",
      "</p>]\n"
     ]
    }
   ],
   "source": [
    "# print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"price\">\n",
       "<span class=\"sale-price\">17,53 €</span>\n",
       "</p>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12,95', '€']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prices[5].get_text(strip=True).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_prices = []\n",
    "# for price in prices:\n",
    "#       original_price = price.find(\"span\", class_=\"rrp\")\n",
    "#       if original_price:\n",
    "#              current_price = str(original_price.previousSibling).strip() # nos quedamos solo con el numero sin etiquetas\n",
    "#              current_price = float(current_price.split(\"€\")[0].replace(\",\", \".\")) # quitamos el signo de euro y reemplazamos la coma por el punto para que python lo reconozca con float\n",
    "#              final_prices.append(current_price)\n",
    "#       else:\n",
    "#              current_price = float(price.get_text(strip=True).split(\"€\")[0].replace(\",\", \".\"))\n",
    "#              final_prices.append(current_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_prices = []\n",
    "# for price in prices:\n",
    "#     original_price = price.find(\"span\", class_=\"sale-price\")\n",
    "#     original_price = original_price.get_text()\n",
    "#     original_price = float(original_price.split(\"€\")[0].replace(\",\", \".\"))\n",
    "#     final_prices.append(original_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_price_compress = [float(price.find(\"span\", class_=\"sale-price\").get_text().split(\" €\")[0].replace(\",\", \".\")) for price in prices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# print(final_prices==final_price_compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recolectar información de un libro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero creamos un soup en la pagína 'principal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libros = soup.find_all(class_='item-img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos en una variable la url principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_principal = 'https://www.bookdepository.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una lista con los urls de los libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_URLs = []\n",
    "# for libro in libros:\n",
    "#     URL_libro = libro.find('a')['href']\n",
    "#     lista_URLs.append(url_principal+URL_libro)\n",
    "\n",
    "# lista_URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a analizar el url de un libro primero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hacemos un nuevo request para el primer libro: \n",
    "# r = requests.get(lista_URLs[0])\n",
    "\n",
    "# # Creamos una sopa específica con la info de cada libro\n",
    "# soup_libro = bs(r.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creamos un soup del primer libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup_libro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el titulo del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Summer I Turned Pretty\n"
     ]
    }
   ],
   "source": [
    "# name = soup_libro.find('h1').text\n",
    "# print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.89"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rating = soup_libro.find(class_ = 'rating-wrap hidden-md')('span')[5].text.split(' ')[-1].replace(',','.')\n",
    "# rating = float(rating)\n",
    "# rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de votaciones para el rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245161"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rating_count = soup_libro.find(class_ = 'rating-wrap hidden-md')('span')[-1].text.split(' ')[-6].replace('(','').replace('.','')\n",
    "# rating_count = int(rating_count)\n",
    "# rating_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipo de formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paperback'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formats = soup_libro.find(class_ = 'meta-info hidden-md')('li')[0].text\n",
    "# formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jenny Han'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# author1 = soup_libro.find(class_ = 'item-info')('span')[-1].text.split('\\n                                    ')[-1]\n",
    "# author1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jenny Han'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# author = soup_libro.find(class_ = 'item-annotation-wrap')('h2')[2].text[6:]\n",
    "# author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.53"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# price = float(soup_libro.find(class_ = 'sale-price').text.split(' ')[0].replace(',','.'))\n",
    "# price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url de la portada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://d1w7fb2mkkr3kw.cloudfront.net/assets/images/book/lrg/9781/4169/9781416968290.jpg'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imagen = soup_libro.find(class_ = 'book-img')['src']\n",
    "# imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo automatizamos para hacer un web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages = np.arange(1, 2)\n",
    "# count = 1\n",
    "# lista_libros = []\n",
    "\n",
    "# for page in pages:\n",
    "    \n",
    "#     URL = 'https://www.bookdepository.com/es/bestsellers?page=' + str(page)\n",
    "#     r = requests.get(URL)\n",
    "#     soup = bs(r.text, 'lxml')\n",
    "#     libros_grid = soup.find_all(class_='item-img')\n",
    "    \n",
    "#     count_libro = 1 # para el print de seguimiento de descarga\n",
    "    \n",
    "#     for libro in libros_grid:\n",
    "#         # Print de seguimiento de descarga:\n",
    "#         print('Libro {} de {}, pag {}/{}'.format(\n",
    "#             count_libro, len(libros_grid), page, len(pages)))\n",
    "\n",
    "#         URL_libro = libro.find('a')['href']\n",
    "#         r = requests.get('https://www.bookdepository.com/' + URL_libro)\n",
    "#         soup_libro = bs(r.text, 'lxml')\n",
    "        \n",
    "#         id_libro = 'lb_' + str(count)\n",
    "        \n",
    "#         name = soup_libro.find('h1').text   \n",
    "#         try:\n",
    "#             price = float(soup_libro.find(class_ = 'sale-price').text.split(' ')[0].replace(',','.'))\n",
    "\n",
    "#         except:\n",
    "#             price = None\n",
    "\n",
    "#         try :\n",
    "#             author = soup_libro.find(class_ = 'item-annotation-wrap')('h2')[2].text[6:]\n",
    "\n",
    "#         except:\n",
    "#             author = soup_libro.find(class_ = 'item-info')('span')[-1].text.split('\\n                                    ')[-1]\n",
    "\n",
    "#         formats = soup_libro.find(class_ = 'meta-info hidden-md')('li')[0].text\n",
    "\n",
    "#         try:\n",
    "#             rating = soup_libro.find(class_ = 'rating-wrap hidden-md')('span')[5].text.split(' ')[-1].replace(',','.')\n",
    "#             rating = float(rating)\n",
    "        \n",
    "#         except:\n",
    "#             rating = None\n",
    "        \n",
    "#         try:    \n",
    "#             rating_count = soup_libro.find(class_ = 'rating-wrap hidden-md')('span')[-1].text.split(' ')[-6].replace('(','').replace('.','')\n",
    "#             rating_count = int(rating_count)\n",
    "        \n",
    "#         except:\n",
    "#             rating_count = None\n",
    "\n",
    "#         imagen = soup_libro.find(class_ = 'book-img')['src']\n",
    "\n",
    "#         data = {\"id_libro\": id_libro,\n",
    "#                 \"name\": name,\n",
    "#                 \"price\": price,\n",
    "#                 \"author\": author,\n",
    "#                 \"format\": formats,\n",
    "#                 \"rating\": rating,\n",
    "#                 \"rating_count\": rating_count,\n",
    "#                 \"imagen\": imagen}\n",
    "\n",
    "#         lista_libros.append(data)\n",
    "        \n",
    "#         # Pasamos al siguiente id\n",
    "#         count += 1\n",
    "#         count_libro += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_libro</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>author</th>\n",
       "      <th>format</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>imagen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lb_1</td>\n",
       "      <td>The Summer I Turned Pretty</td>\n",
       "      <td>17.53</td>\n",
       "      <td>Jenny Han</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>3.89</td>\n",
       "      <td>245161.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lb_2</td>\n",
       "      <td>Heaven Official's Blessing: Tian Guan Ci Fu (N...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>ZeldaCW</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.79</td>\n",
       "      <td>628.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lb_3</td>\n",
       "      <td>It Ends With Us: The most heartbreaking novel ...</td>\n",
       "      <td>12.89</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1178344.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lb_4</td>\n",
       "      <td>Heartstopper Volume 3 : The million-copy bests...</td>\n",
       "      <td>14.46</td>\n",
       "      <td>Alice Oseman</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.64</td>\n",
       "      <td>216345.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lb_5</td>\n",
       "      <td>Heartstopper Volume 2 : The million-copy bests...</td>\n",
       "      <td>14.15</td>\n",
       "      <td>Alice Oseman</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.62</td>\n",
       "      <td>253424.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lb_6</td>\n",
       "      <td>Seven Husbands of Evelyn Hugo : The Sunday Tim...</td>\n",
       "      <td>12.95</td>\n",
       "      <td>Taylor Jenkins Reid</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.48</td>\n",
       "      <td>1179179.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lb_7</td>\n",
       "      <td>Where the Crawdads Sing</td>\n",
       "      <td>12.79</td>\n",
       "      <td>Delia Owens</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1780708.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lb_8</td>\n",
       "      <td>Verity : The thriller that will capture your h...</td>\n",
       "      <td>12.37</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.43</td>\n",
       "      <td>823944.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lb_9</td>\n",
       "      <td>It's Not Summer Without You (Reprint)</td>\n",
       "      <td>17.34</td>\n",
       "      <td>Jenny Han</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.02</td>\n",
       "      <td>163323.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lb_10</td>\n",
       "      <td>Heartstopper Volume 1 : The million-copy bests...</td>\n",
       "      <td>14.15</td>\n",
       "      <td>Alice Oseman</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.55</td>\n",
       "      <td>337901.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lb_11</td>\n",
       "      <td>Heartstopper Volume 4 : The million-copy bests...</td>\n",
       "      <td>15.25</td>\n",
       "      <td>Alice Oseman</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.68</td>\n",
       "      <td>171841.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lb_12</td>\n",
       "      <td>Twisted Love</td>\n",
       "      <td>14.98</td>\n",
       "      <td>Ana Huang</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>3.80</td>\n",
       "      <td>84556.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lb_13</td>\n",
       "      <td>Ugly Love</td>\n",
       "      <td>13.21</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.25</td>\n",
       "      <td>652795.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lb_14</td>\n",
       "      <td>We'll Always Have Summer (Reprint)</td>\n",
       "      <td>17.34</td>\n",
       "      <td>Jenny Han</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.02</td>\n",
       "      <td>137552.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lb_15</td>\n",
       "      <td>Owning It : The Ride that Changed my Life</td>\n",
       "      <td>23.51</td>\n",
       "      <td>Brad Smeele</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lb_16</td>\n",
       "      <td>Twisted Games</td>\n",
       "      <td>13.23</td>\n",
       "      <td>Ana Huang</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.12</td>\n",
       "      <td>53243.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lb_17</td>\n",
       "      <td>The Scum Villain's Self-Saving System: Ren Zha...</td>\n",
       "      <td>21.67</td>\n",
       "      <td>Xiao Tong Kong (Velinxi)</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.05</td>\n",
       "      <td>133.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lb_18</td>\n",
       "      <td>Atomic Habits : the life-changing million-copy...</td>\n",
       "      <td>20.91</td>\n",
       "      <td>James Clear</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.38</td>\n",
       "      <td>398537.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lb_19</td>\n",
       "      <td>Twisted Lies</td>\n",
       "      <td>15.64</td>\n",
       "      <td>31,83 €</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.54</td>\n",
       "      <td>305.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lb_20</td>\n",
       "      <td>The Hong Kong Diaries</td>\n",
       "      <td>63.83</td>\n",
       "      <td>Chris Patten</td>\n",
       "      <td>Hardback</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lb_21</td>\n",
       "      <td>Twisted Hate</td>\n",
       "      <td>13.44</td>\n",
       "      <td>Ana Huang</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.23</td>\n",
       "      <td>38691.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lb_22</td>\n",
       "      <td>Reminders of Him : A Novel</td>\n",
       "      <td>14.88</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.55</td>\n",
       "      <td>294532.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lb_23</td>\n",
       "      <td>The Love Hypothesis</td>\n",
       "      <td>13.67</td>\n",
       "      <td>Ali Hazelwood</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.34</td>\n",
       "      <td>526310.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lb_24</td>\n",
       "      <td>Nick and Charlie</td>\n",
       "      <td>12.99</td>\n",
       "      <td>Alice Oseman</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.28</td>\n",
       "      <td>40370.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lb_25</td>\n",
       "      <td>The Midnight Library : The No.1 Sunday Times b...</td>\n",
       "      <td>12.81</td>\n",
       "      <td>Matt Haig</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.05</td>\n",
       "      <td>987858.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lb_26</td>\n",
       "      <td>Before the Coffee Gets Cold</td>\n",
       "      <td>14.21</td>\n",
       "      <td>Geoffrey Trousselot</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>3.75</td>\n",
       "      <td>103849.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lb_27</td>\n",
       "      <td>The Scum Villains Self-Saving System: Ren Zha ...</td>\n",
       "      <td>25.04</td>\n",
       "      <td>Xiao Tong Kong (Velinxi)</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>4.19</td>\n",
       "      <td>98.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lb_28</td>\n",
       "      <td>Solitaire</td>\n",
       "      <td>14.59</td>\n",
       "      <td>Alice Oseman</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>3.82</td>\n",
       "      <td>37441.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lb_29</td>\n",
       "      <td>Berserk Deluxe Volume 1</td>\n",
       "      <td>50.68</td>\n",
       "      <td>Kentaro Miura</td>\n",
       "      <td>Hardback</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4070.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lb_30</td>\n",
       "      <td>Our Cosmic Origin : Knowledge in preparation f...</td>\n",
       "      <td>22.53</td>\n",
       "      <td>Richard Barnett</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_libro                                               name  price  \\\n",
       "0      lb_1                         The Summer I Turned Pretty  17.53   \n",
       "1      lb_2  Heaven Official's Blessing: Tian Guan Ci Fu (N...  19.26   \n",
       "2      lb_3  It Ends With Us: The most heartbreaking novel ...  12.89   \n",
       "3      lb_4  Heartstopper Volume 3 : The million-copy bests...  14.46   \n",
       "4      lb_5  Heartstopper Volume 2 : The million-copy bests...  14.15   \n",
       "5      lb_6  Seven Husbands of Evelyn Hugo : The Sunday Tim...  12.95   \n",
       "6      lb_7                            Where the Crawdads Sing  12.79   \n",
       "7      lb_8  Verity : The thriller that will capture your h...  12.37   \n",
       "8      lb_9              It's Not Summer Without You (Reprint)  17.34   \n",
       "9     lb_10  Heartstopper Volume 1 : The million-copy bests...  14.15   \n",
       "10    lb_11  Heartstopper Volume 4 : The million-copy bests...  15.25   \n",
       "11    lb_12                                       Twisted Love  14.98   \n",
       "12    lb_13                                          Ugly Love  13.21   \n",
       "13    lb_14                 We'll Always Have Summer (Reprint)  17.34   \n",
       "14    lb_15          Owning It : The Ride that Changed my Life  23.51   \n",
       "15    lb_16                                      Twisted Games  13.23   \n",
       "16    lb_17  The Scum Villain's Self-Saving System: Ren Zha...  21.67   \n",
       "17    lb_18  Atomic Habits : the life-changing million-copy...  20.91   \n",
       "18    lb_19                                       Twisted Lies  15.64   \n",
       "19    lb_20                              The Hong Kong Diaries  63.83   \n",
       "20    lb_21                                       Twisted Hate  13.44   \n",
       "21    lb_22                         Reminders of Him : A Novel  14.88   \n",
       "22    lb_23                                The Love Hypothesis  13.67   \n",
       "23    lb_24                                   Nick and Charlie  12.99   \n",
       "24    lb_25  The Midnight Library : The No.1 Sunday Times b...  12.81   \n",
       "25    lb_26                        Before the Coffee Gets Cold  14.21   \n",
       "26    lb_27  The Scum Villains Self-Saving System: Ren Zha ...  25.04   \n",
       "27    lb_28                                          Solitaire  14.59   \n",
       "28    lb_29                            Berserk Deluxe Volume 1  50.68   \n",
       "29    lb_30  Our Cosmic Origin : Knowledge in preparation f...  22.53   \n",
       "\n",
       "                      author     format  rating  rating_count  \\\n",
       "0                  Jenny Han  Paperback    3.89      245161.0   \n",
       "1                    ZeldaCW  Paperback    4.79         628.0   \n",
       "2             Colleen Hoover  Paperback    4.42     1178344.0   \n",
       "3               Alice Oseman  Paperback    4.64      216345.0   \n",
       "4               Alice Oseman  Paperback    4.62      253424.0   \n",
       "5        Taylor Jenkins Reid  Paperback    4.48     1179179.0   \n",
       "6                Delia Owens  Paperback    4.45     1780708.0   \n",
       "7             Colleen Hoover  Paperback    4.43      823944.0   \n",
       "8                  Jenny Han  Paperback    4.02      163323.0   \n",
       "9               Alice Oseman  Paperback    4.55      337901.0   \n",
       "10              Alice Oseman  Paperback    4.68      171841.0   \n",
       "11                 Ana Huang  Paperback    3.80       84556.0   \n",
       "12            Colleen Hoover  Paperback    4.25      652795.0   \n",
       "13                 Jenny Han  Paperback    4.02      137552.0   \n",
       "14               Brad Smeele  Paperback     NaN           NaN   \n",
       "15                 Ana Huang  Paperback    4.12       53243.0   \n",
       "16  Xiao Tong Kong (Velinxi)  Paperback    4.05         133.0   \n",
       "17               James Clear  Paperback    4.38      398537.0   \n",
       "18                   31,83 €  Paperback    4.54         305.0   \n",
       "19              Chris Patten   Hardback     NaN           NaN   \n",
       "20                 Ana Huang  Paperback    4.23       38691.0   \n",
       "21            Colleen Hoover  Paperback    4.55      294532.0   \n",
       "22             Ali Hazelwood  Paperback    4.34      526310.0   \n",
       "23              Alice Oseman  Paperback    4.28       40370.0   \n",
       "24                 Matt Haig  Paperback    4.05      987858.0   \n",
       "25       Geoffrey Trousselot  Paperback    3.75      103849.0   \n",
       "26  Xiao Tong Kong (Velinxi)  Paperback    4.19          98.0   \n",
       "27              Alice Oseman  Paperback    3.82       37441.0   \n",
       "28             Kentaro Miura   Hardback    4.63        4070.0   \n",
       "29           Richard Barnett  Paperback    3.00           3.0   \n",
       "\n",
       "                                               imagen  \n",
       "0   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "1   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "2   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "3   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "4   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "5   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "6   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "7   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "8   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "9   https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "10  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "11  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "12  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "13  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "14  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "15  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "16  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "17  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "18  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "19  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "20  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "21  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "22  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "23  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "24  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "25  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "26  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "27  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "28  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  \n",
       "29  https://d1w7fb2mkkr3kw.cloudfront.net/assets/i...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(lista_libros)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afde6861a040563f15a2ec1b440faf84809f9a7bcc3c75cfd11a60e7dd448719"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
